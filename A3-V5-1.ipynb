{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12b09e08-729d-4df0-814f-d49e7f084f61",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "    <h3>NOTE</h3>\n",
    "    <p>Before you submit this assignment, <strong>make sure everything runs as expected</strong>:</p>\n",
    "    <ol>\n",
    "        <li><strong>restart the kernel</strong> (in the menubar, select <strong>Kernel → Restart</strong>)\n",
    "        <li><strong>run all cells</strong> (in the menubar, select <strong>Cell → Run All</strong>)</li>\n",
    "    </ol>\n",
    "    <p>Make sure to complete every cell that states \"<strong><TT>YOUR CODE IN THIS CELL</TT></strong>\".</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3a6163-b141-402e-8ab1-b330d7f0832a",
   "metadata": {
    "tags": []
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e22d54-a7e5-4612-9ed1-da05c1a74432",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <h2>CHANGELOG</h2>\n",
    "    <h3>A3-V5.ipynb</h3>\n",
    "    <p>Nov 29, 2021</br>\n",
    "    The following revisions have been added to <strong>A3-V4.ipynb</strong>.</p>\n",
    "    <ul>\n",
    "        <li>added code for <strong>Voting Ensemble</strong> for regression</li>\n",
    "        <li>added example code to <strong>Plotting & Visualizations</strong> subsection</li>\n",
    "        <li>reduced weight of the <strong>Final Report</strong> section</li>\n",
    "        <li>added <strong>tfds-nightly</strong> package to list of packages to import</li>\n",
    "        <li>explained the evaluation process in <strong>Task: Evaluation</strong></li>\n",
    "        <li>added code to <strong>Task: Evaluation</strong> for evaluating a model</li>\n",
    "        <li>added <strong>pandas</strong> as a package to import</li>\n",
    "        <li>added <strong>pandas DataFrames</strong> tutorial examples under <strong>Task: New Toxic Comments Dataset</strong> for tips on accessing the datasets more easily</li>\n",
    "        <li>added code for SVM for regression to <strong>Task: SVM Classification</strong></li>\n",
    "        <li>removed \"Fit the model\" comments from each model's code cell since it was redundant (already had \"Train the model\")</li>\n",
    "        <li>finished adding code to <strong>Neural Network</strong> task</li>\n",
    "        <li>updated number of marks <strong>Neural Network</strong> task from 10 marks to 5 marks</li>\n",
    "        <!-- <li></li> -->\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069c7ed8-51e8-4640-a6a5-53fffeedbaa9",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <h2>CHANGELOG</h2>\n",
    "    <h3>A3-V4.ipynb</h3>\n",
    "    <p>Nov 24, 2021</br>\n",
    "    The following revisions have been added to <strong>A3-V3.ipynb</strong>.</p>\n",
    "    <ul>\n",
    "        <li>added code cell to <em>Evaluation</em> & <em>Discussion</em> sections of the <strong>Project Report</strong> for demonstrating visualization capabilities</li>\n",
    "        <li>added additional comment steps to <strong>Language Model</strong> task</li>\n",
    "        <li>updated marks for <strong>Language Model</strong> task</li>\n",
    "        <li>added <strong>PRO TIPS</strong> throughout document</li>\n",
    "        <li>updated pseudocode for <strong>Extract Features From Dataset</strong></li>\n",
    "        <li>added code to <strong>Neural Network</strong> task</li>\n",
    "        <li>added comments to <strong>Decision Tree</strong> task</li>\n",
    "        <li>added explanation (from <strong>Discord</strong>) of <strong>Extract Features From Dataset</strong> task</li>\n",
    "        <li>added regression and classification implementations to each model</li>\n",
    "        <li>added <strong>Plotting & Visualizations</strong> subsection</li>\n",
    "        <li>added explanation (from <strong>Discord</strong>) of <strong>What You Are Being Asked To Do</strong> subsection</li>\n",
    "        <!-- <li></li> -->\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e496991c-edd6-43de-bc5e-9ca302b8b5be",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <h3>A3-V3.ipynb</h3>\n",
    "    <p>Nov 19, 2021</br>\n",
    "    The following revisions have been added to <strong>A3-V2.ipynb</strong>.</p>\n",
    "    <p>Extract Features From Dataset:\n",
    "    <ul>\n",
    "        <li>updated description of <strong>Extract Features From Dataset</strong></li>\n",
    "        <li>updated how many marks <strong>Extract Features From Dataset</strong> is out of</li>\n",
    "        <li>provided a breakdown of the marks in <strong>Extract Features From Dataset</strong></li>\n",
    "        <li>added code examples to <strong>Extract Features From Dataset</strong></li>\n",
    "    </ul>\n",
    "    <p>Miscellaneous:\n",
    "    <ul>\n",
    "        <li>marking rubric updated for some <strong>Tasks</strong> (but not yet finalized)</li>\n",
    "        <li>added comments for all EXAMPLE CODE to be commented out</li>\n",
    "        <li>added comments for removing <tt>raise NotImplementedError()</tt> once the code cell has begun being implemented</li>\n",
    "        <li>new <strong>TODOs</strong> added (these are for the instructor to complete)</li>\n",
    "    </ul>\n",
    "    </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1bf3597-866c-4551-bbe6-29f3cf84ad6b",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <h3>A3-V2.ipynb</h3>\n",
    "    <p>Nov 18, 2021</br>\n",
    "    The following revisions have been added to <strong>A3-V1.ipynb</strong>:</p>\n",
    "    <ul>\n",
    "        <li>added <strong>Changelog</strong></li>\n",
    "        <li>added code and a description to the <strong>Decision Tree</strong></li>\n",
    "        <li>added code to the <strong>Voting Ensemble</strong></li>\n",
    "        <li>added code for <strong>SVM Classifier</strong></li>\n",
    "        <li>added code for <strong>Decision Tree Classifier</strong></li>\n",
    "        <li>added to the <strong>Overview</strong> section to compare the task to other tasks</li>\n",
    "        <li>updated code description for <strong>n-gram Language Model</strong></li>\n",
    "        <li>added new dataset from just announced <strong>Kaggle</strong> competition on identifying toxic comments  <strong>→</strong>  <strong>$50,000</strong></li>\n",
    "        <li>transitioned to new evaluation metric taken from the just announced <strong>Kaggle</strong> competition on identifying toxic comments</li>\n",
    "        <li>changed font to light gray color for the <strong>Toxic Comments Dataset (OLD COMPETITION)</strong> since this dataset isn't the one provided by the new competition</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52702c8-7675-4abb-aa81-1e0f18a834f7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "    <h4><strong>TODO</strong></h4>\n",
    "    <p>The following items need to be included by the instructor in this assignment:</p>\n",
    "    <ul>\n",
    "        <li>need to add code to <strong>Neural Network</strong></li>\n",
    "        <li>add example code to <strong>Plotting & Visualizations</strong> subsection</li>\n",
    "        <li>marking rubric not finalized</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ccb7fe1-25eb-42df-ac84-6828ca20606a",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "# Assignment #3: Version 5\n",
    "**CMPT-310: Fall 2021**\n",
    "\n",
    "\n",
    "**NOTE:** Complete **Quiz #4** prior to beginning this assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4499febe-b6ed-4a36-b4dc-a643e9b81224",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Objectives\n",
    "\n",
    "* access a *real-world* dataset (e.g., used in **kaggle.com** competitions, etc.) rather than a *toy* dataset\n",
    "* implement a variety of machine learning models\n",
    "* download and apply *pre-trained machine learning models*\n",
    "* develop and evaluate ensembles of models\n",
    "* evaluate different machine learning models on *complex* real-world tasks\n",
    "* work with a variety of industry-standard machine learning libraries (*Tensorflow*, *PyTorch*, *sklearn*, *NLTK*, etc.)\n",
    "* visually communicate data and experimental results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37678043-d48b-4205-b71f-72f3fb41ab71",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Instructions\n",
    "\n",
    "Write your **code** in the *code cells* located directly below each red *Write Code* block.\\\n",
    "Write your **text** in the *Markdown cells* that follow every **Task** description below. Also complete this Notebook's **Final Report** section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3983737",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    <h4>PRO TIP</h4>\n",
    "    <p>The best approach to this assignment is to work on <strong>one task at a time</strong>. Treat each task as a step toward a destination.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4f2825-6b22-4378-a31a-d02e923559bc",
   "metadata": {
    "tags": []
   },
   "source": [
    "------\n",
    "## Preliminaries & Dependencies\n",
    "\n",
    "You will require the following **Python** packages to complete this assignment (it is likely many of these libraries are already installed via **Anaconda**, **Quiz #4**, etc.):\n",
    "* matplotlib\n",
    "* numpy\n",
    "* sklearn\n",
    "* tensorflow\n",
    "* tensorflow-hub\n",
    "* tensorflow-datasets\n",
    "* tfds-nightly\n",
    "* seaborn\n",
    "* nltk\n",
    "* pandas\n",
    "\n",
    "\n",
    "### Imports\n",
    "\n",
    "Import the following libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e084519-9419-4f64-8287-38c245f19138",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import IPython.display as display\n",
    "import seaborn\n",
    "import sklearn\n",
    "import nltk\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e51feb5-8e31-4bf6-b468-608f17ea7717",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "## Cross Validation Of A Dataset\n",
    "\n",
    "The following example code demonstrates using the builtin cross validation module from the [**Scikit-Learn** library](https://scikit-learn.org/stable/modules/cross_validation.html).\\\n",
    "You will likely use a variation of the following code for all of the models you will be evaluating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af18121c-0c1a-4cf0-a0c9-d627981376aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((150, 4), (150,))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# EXAMPLE CODE: COMMENT OUT THIS CODE CELL AFTER IMPLEMENTING YOUR CODE\n",
    "\n",
    "# Code from:  https://scikit-learn.org/stable/modules/cross_validation.html\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from sklearn import svm\n",
    "\n",
    "# X = inputs or features of the data\n",
    "# y = output values from the data that we are trying to predict\n",
    "X, y = datasets.load_iris(return_X_y=True)\n",
    "\n",
    "X.shape, y.shape # shape displays the dimensions of the matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ff3faad-8a83-4d2b-b921-8f44bef5c0ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120, 4) (120,)\n",
      "(30, 4) (30,)\n",
      "The performance of one run of the SVM model: 1.0\n"
     ]
    }
   ],
   "source": [
    "# EXAMPLE CODE: COMMENT OUT THIS CODE CELL AFTER IMPLEMENTING YOUR CODE\n",
    "\n",
    "# Train the model using 80% of the dataset then test (evaluate) the model on the other 20% of the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# shape displays the dimensions of the matrices\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)\n",
    "\n",
    "clf = svm.SVC(kernel='linear', C=1).fit(X_train, y_train)\n",
    "score = clf.score(X_test, y_test)\n",
    "print(\"The performance of one run of the SVM model:\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d21809e3-a739-48dd-81ab-f21682a21cfa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores for the 5 runs of the SVM model: [0.96666667 1.         0.96666667 0.96666667 1.        ]\n",
      "0.98 accuracy with a standard deviation of 0.02\n"
     ]
    }
   ],
   "source": [
    "# EXAMPLE CODE: COMMENT OUT THIS CODE CELL AFTER IMPLEMENTING YOUR CODE\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "clf = svm.SVC(kernel='linear', C=1, random_state=42)\n",
    "\n",
    "scores = cross_val_score(clf, X, y, cv=5)\n",
    "print(\"Scores for the 5 runs of the SVM model:\", scores)\n",
    "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914dd17f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# ----\n",
    "## Task: New Toxic Comments Dataset   (5 Marks)\n",
    "\n",
    "See https://www.kaggle.com/c/jigsaw-toxic-severity-rating.\n",
    "\n",
    "From [**Kaggle**](https://www.kaggle.com/c/jigsaw-toxic-severity-rating/data):\n",
    "> In this competition you will be ranking comments in order of severity of toxicity. You are given a list of comments, and each comment should be scored according to their relative toxicity. Comments with a higher degree of toxicity should receive a higher numerical value compared to comments with a lower degree of toxicity.\n",
    "> \n",
    "> **Disclaimer:** The dataset for this competition contains text that may be considered *profane, vulgar, or offensive*.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Data Description\n",
    "\n",
    "\"*Your task is to predict a score that represents the relative toxic severity of the comment. Comments with a higher degree of toxicity should receive a higher numerical value compared to comments with a lower degree of toxicity; scores are relative, and not constrained to a certain range of values.*\"\n",
    "\n",
    "> Note, there is no training data for this competition. You can refer to previous Jigsaw competitions for data that might be useful to train models. But note that the task of previous competitions has been to predict the probability that a comment was toxic, rather than the degree or severity of a comment's toxicity.\n",
    "> \n",
    "> **Toxic Comment Classification Challenge**\\\n",
    "> **Jigsaw Unintended Bias in Toxicity Classification**\\\n",
    "> **Jigsaw Multilingual Toxic Comment Classification**\n",
    "> \n",
    "> While we don't include training data, we do provide a set of paired toxicity rankings that can be used to validate models.\n",
    "> \n",
    "> #### Files\n",
    "> \n",
    "> **comments_to_score.csv** - for each comment text in this file, your task is to predict a score that represents the relative toxic severity of the comment. Comments with a higher degree of toxicity should receive a higher numerical value compared to comments with a lower degree of toxicity; scores are relative, and not constrained to a certain range of values. NOTE: the rerun version of this file has ~14k comments that will be scored by your submitted model.\\\n",
    "> **sample_submission.csv** - a sample submission file in the correct format\\\n",
    "> **validation_data.csv** - pair rankings that can be used to validate models; this data includes the annotator worker id, and how that annotator ranked a given pair of comments; note, this data contains comments that are not found in comments_to_score.\n",
    "\n",
    "\n",
    "### What You Are Being Asked To Do\n",
    "\n",
    "(A version of this is posted on **Discord**)\n",
    "\n",
    "The file `validation_data.csv` has examples of comment pairs for you to test your model against (*I don't recommend reading the toxic comments though!*).\n",
    "\n",
    "![Contents of validation_data.csv file.](./images/Toxic-comment-database-examples.png)\n",
    "\n",
    "The above image shows the first few rows of the `validation_data.csv` file. Each row contains a pair of comments. The column on the right contains comments that are more toxic than the comments in the left column. The comment pairs in the `validation_data.csv` file was ranked by human annotators.\n",
    "\n",
    "Our job is to provide every comment with a **toxicity score**. To check how accurate our scoring was, two random comments are selected and we compare which comment was identifed to be more toxic.\n",
    "\n",
    "An example of what you are being asked to do:\n",
    "* give your model the comment `This article sucks woo woo wooooooo`, which the model assigns the comment a **toxicity score** (say a score of 20)\n",
    "* give your model another comment  such as `WHAT!!!!!!!!?!?!!?!?!!?!?!?!?!!!!!!!!!!!!!!!!!!!!!!!!???????????????????????????????????????????????...`, which the model assigns the comment a **toxicity score** (say a score of 50)\n",
    "* continue scoring *all* of the comments in `comments_to_score.csv`\n",
    "* in the competition, **Kaggle** will take the scores and compare them to two of the comments that humans determined which was more toxic\n",
    "* if your scoring matches the human rankings (i.e., the \"*more toxic*\" comment gets a higher score than the \"*less toxic*\" comment) then the model got that comparison correct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ca4a3a-842b-40e1-873f-404fbf7d8957",
   "metadata": {},
   "source": [
    "<font color=lightgray>\n",
    "    \n",
    "## Resource: Civil Comments Dataset   (2 YEAR OLD COMPETITION)\n",
    "\n",
    "Note this a **large** dataset: 758 Mb. You are not required to use this dataset (although it appears very helpful).\\\n",
    "\"*This dataset is a replica of the data released for the Jigsaw Toxic Comment Classification Challenge and Jigsaw Multilingual Toxic Comment Classification competition on Kaggle, with the test dataset merged with the test_labels released after the end of the competitions*\".\n",
    "\n",
    "**Kaggle** had a competition **Jigsaw Unintended Bias in Toxicity Classification** where they \"detect toxic comments while minimizing unintended model bias\".\\\n",
    "See https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge.\n",
    "\n",
    "From **Kaggle**'s website:\n",
    "> When the Conversation AI team first built toxicity models, they found that the models incorrectly learned to associate the names of frequently attacked identities with toxicity. Models predicted a high likelihood of toxicity for comments containing those identities (e.g. \"gay\"), even when those comments were not actually toxic (such as \"I am a gay woman\"). This happens because training data was pulled from available sources where unfortunately, certain identities are overwhelmingly referred to in offensive ways. Training a model from data with these imbalances risks simply mirroring those biases back to users.\n",
    "> \n",
    "> In this competition, you're challenged to build a model that recognizes toxicity and minimizes this type of unintended bias with respect to mentions of identities. You'll be using a dataset labeled for identity mentions and optimizing a metric designed to measure unintended bias. Develop strategies to reduce unintended bias in machine learning models, and you'll help the Conversation AI team, and the entire industry, build models that work well for a wide range of conversations.\n",
    "> \n",
    "> **Disclaimer:** the dataset for this competition contains text that may be considered *profane*, *vulgar*, or *offensive*.\n",
    "\n",
    "### Data Description\n",
    "\n",
    "From **Kaggle**:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc0a411-8b50-4943-a6cc-e6b7e94c16f9",
   "metadata": {},
   "source": [
    "<font color=lightgray>\n",
    "    \n",
    "## Resource: Toxic Comments Dataset   (4 YEAR OLD COMPETITION)\n",
    "\n",
    "**Kaggle** has a competition identifying *toxic comments*.\\\n",
    "See https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge.\n",
    "\n",
    "From **Kaggle**'s website:\n",
    "> ...tools to help improve online conversation. One area of focus is the study of negative online behaviors, like toxic comments (i.e. comments that are rude, disrespectful or otherwise likely to make someone leave a discussion). So far they’ve built a range of publicly available models served through the Perspective API, including toxicity. But the current models still make errors, and they don’t allow users to select which types of toxicity they’re interested in finding (e.g. some platforms may be fine with profanity, but not with other types of toxic content).\n",
    "> \n",
    "> In this competition, you’re challenged to build a multi-headed model that’s capable of detecting different types of of toxicity like threats, obscenity, insults, and identity-based hate better than Perspective’s current models. You’ll be using a dataset of comments from Wikipedia’s talk page edits. Improvements to the current model will hopefully help online discussion become more productive and respectful.\n",
    "> \n",
    "> **Disclaimer:** the dataset for this competition contains text that may be considered *profane*, *vulgar*, or *offensive*.\n",
    "\n",
    "### Data Description\n",
    "\n",
    "From **Kaggle**:\n",
    "> You are provided with a large number of Wikipedia comments which have been labeled by human raters for toxic behavior. The types of toxicity are:\n",
    "> * toxic\n",
    "> * severe_toxic\n",
    "> * obscene\n",
    "> * threat\n",
    "> * insult\n",
    "> * identity_hate\n",
    ">\n",
    "> You must create a model which predicts a probability of each type of toxicity for each comment.\n",
    "> \n",
    "> File Descriptions:\n",
    "> * **train.csv** - the training set, contains comments with their binary labels\n",
    "> * **test.csv** - the test set, you must predict the toxicity probabilities for these comments. To deter hand labeling, the test set contains some comments which are not included in scoring.\n",
    "> * **sample_submission.csv** - a sample submission file in the correct format\n",
    "> * **test_labels.csv** - labels for the test data; value of -1 indicates it was not used for scoring; (Note: file added after competition close!)\n",
    "\n",
    "Our **goal** is to predict for each comment the *probability* of each type of toxicity.\n",
    "This is a multi-class classification task (i.e., *more than two categories, more than two labels, more than two classes*, etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ece326-df7e-418d-b366-4184595bd4f5",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Download The Datasets\n",
    "\n",
    "Download the datasets from **Kaggle** (under the **Data** tab):\\\n",
    "[old dataset - \"Toxic Comment Classification Challenge\"](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/data)\\\n",
    "[old dataset - \"Jigsaw Unintended Bias in Toxicity Classification\"](https://www.kaggle.com/c/jigsaw-unintended-bias-in-toxicity-classification/data)\\\n",
    "[new dataset - \"Jigsaw Rate Severity of Toxic Comments\"](https://www.kaggle.com/c/jigsaw-toxic-severity-rating/data)\n",
    "\n",
    "Or download the dataset from **Canvas** under **Files** > **Data**:\\\n",
    "[Kaggle-Toxic-Comments-Dataset (OLD)](https://canvas.sfu.ca/files/17538324/download?download_frd=1)\\\n",
    "[Kaggle-Toxic-Comments-Dataset-With-Bias (OLD)](https://canvas.sfu.ca/files/17742270/download?download_frd=1) (note this is a **756 Mb** file)\\\n",
    "[Kaggle-Toxic-Comments-Dataset (NEW)](https://canvas.sfu.ca/files/17622704/download?download_frd=1) is the dataset we will be using to evaluate our model.\n",
    "\n",
    "Or download the datasets from **Tensorflow** (you can then convert the dataset to a **Dataframes** object if you are more comfortable with **Dataframes**).\\\n",
    "[Overview of Dataframes](https://pandas.pydata.org/pandas-docs/stable/user_guide/10min.html).\\\n",
    "The code to download the datasets via **Tensorflow**'s data repository:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3aaac489-97a5-47cc-a2d9-38be6df8b43f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# One way to download the data is through Tensorflow's Datasets repository\n",
    "# Data is stored at:\n",
    "#    ~/tensorflow_datasets/wikipedia_toxicity_subtypes/\n",
    "#    ~/tensorflow_datasets/civil_comments/CivilComments/\n",
    "# Dataset sizes are:\n",
    "#    2 Gb - wikipedia_toxicity_subtypes\n",
    "#    1 Gb - civil_comments\n",
    "# This code cell takes about 5-10 minutes to execute\n",
    "# You only need to run this code cell once. If you run it again it doesn't\n",
    "#     do anything since the datasets have already been downloaded\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "# Construct a tf.data.Dataset\n",
    "ds_wikipedia_comments = tfds.load('wikipedia_toxicity_subtypes')\n",
    "ds_comment_bias = tfds.load('civil_comments')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1029f4f1-ff35-4321-9fec-c077b7be0a13",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>identity_attack</th>\n",
       "      <th>insult</th>\n",
       "      <th>obscene</th>\n",
       "      <th>severe_toxicity</th>\n",
       "      <th>text</th>\n",
       "      <th>threat</th>\n",
       "      <th>toxicity</th>\n",
       "      <th>E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'Question\\nWhat was wrong with the repair I d...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>two</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'Kisumu \\n\\nI saw that you contributed to Kis...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>four</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   identity_attack  insult  obscene  severe_toxicity  \\\n",
       "2              0.0     0.0      0.0              0.0   \n",
       "4              0.0     0.0      0.0              0.0   \n",
       "\n",
       "                                                text  threat  toxicity     E  \n",
       "2  b'Question\\nWhat was wrong with the repair I d...     0.0       0.0   two  \n",
       "4  b'Kisumu \\n\\nI saw that you contributed to Kis...     0.0       0.0  four  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Code from: https://www.tensorflow.org/datasets/overview#tfdsas_dataframe\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "import pandas\n",
    "\n",
    "# working with DataFrames\n",
    "dset, info = tfds.load('wikipedia_toxicity_subtypes', with_info=True)\n",
    "dframe = tfds.as_dataframe(dset[\"train\"].take(1000), info) # only takes the first 1000 data samples\n",
    "#dframe = tfds.as_dataframe(dset[\"train\"], info) # takes all the data into memory (takes a while)\n",
    "\n",
    "# display first few rows & last few rows\n",
    "dframe.head()\n",
    "dframe.tail()\n",
    "\n",
    "# display column names\n",
    "dframe.columns\n",
    "\n",
    "# statistic summary of the data\n",
    "dframe.describe()\n",
    "\n",
    "# selecting the \"text\" column (these do the same thing)\n",
    "dframe[\"text\"]\n",
    "dframe.text\n",
    "\n",
    "# selecting the \"insult\" column (these do the same thing)\n",
    "dframe[\"insult\"]\n",
    "dframe.insult\n",
    "\n",
    "# getting the comment text from the 10th comment in the dataset\n",
    "dframe[\"text\"][9]\n",
    "\n",
    "# selecting rows 10 to 15\n",
    "dframe[10:16]\n",
    "\n",
    "# selecting all the comments that are labelled as an insult\n",
    "dframe[dframe[\"insult\"] > 0]\n",
    "\n",
    "# fancy advanced:\n",
    "#    selects the comments where column \"E\" has either the value of \"two\" or \"four\"\n",
    "dframe = tfds.as_dataframe(dset[\"train\"].take(6), info) # only takes the first 6 data samples\n",
    "dframe2 = dframe.copy()\n",
    "dframe2[\"E\"] = [\"one\", \"one\", \"two\", \"three\", \"four\", \"three\"]\n",
    "dframe2[dframe2[\"E\"].isin([\"two\", \"four\"])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d1b645-5626-4955-b00e-c14154a9d565",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <h3>Other Datasets To Use</h3>\n",
    "    <p>Using additional datasets is optional (though likely to be helpful). Other datasets you can use to supplement the above datasets:</br>\n",
    "    <a href=\"https://www.kaggle.com/carlaperezalmendros/dont-patronize-me\">Don't Patronize Me!</a>  (you will need to sign a privacy form to access the dataset)</br>\n",
    "    Others?</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0101614c",
   "metadata": {},
   "source": [
    "----\n",
    "<div class=\"alert alert-info\">\n",
    "    <h4>PRO TIP</h4>\n",
    "    <p>Extract at least one or two features before implementing any of the models.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574fe49c-0488-46f7-8073-36b71989aac2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Task: Extract Features From Dataset   (40 Marks)\n",
    "\n",
    "Use **NLTK** to extract **features** from the **Toxic Comments** dataset.\\\n",
    "The **features** will be used to train various Machine Learning models to identify toxic comments.\n",
    "\n",
    "Possible **features** to extract:\n",
    "* check if a word is in a list of swear words, or a list of words that are hate speech\n",
    "* check if punctuation is used in the *body* of a word rather than at the end of the sentence\n",
    "* check if words such as `a$$` are used where letters are replaced by visually similar symbols\n",
    "* sentence length i.e., how many words a sentence has\n",
    "* average word length in a sentence\n",
    "* unusually high number of exclamation marks, which could represent the author being frustrated or angry\n",
    "* etc.\n",
    "\n",
    "\n",
    "### Transforming Data Into Features\n",
    "\n",
    "We represent the data as matrices/vectors. So we are transforming the dataset into a matrix representation. None of the models accept text input! Example:\\\n",
    "`X = [[0, 0], [1, 3], [2, 0], [3, 1]]`\\\n",
    "`Y = [0, 1, 2, 3]`\n",
    "\n",
    "`X` is a features matrix.\n",
    "`Y` is a matrix of the target classes/output the model is trying to predict. In this case we have four classes `[0, 1, 2, 3]`. The actual classes could be non-toxic, toxic, very toxic, and extremely toxic, but we have to replace them by a number.\n",
    "\n",
    "In `X` we have four samples/datapoints/examples, the first being `[0, 0]`. Each column in the sample corresponds to a feature.\\\n",
    "For example, the first column could be number of swear words in comment and the 2nd column could be percentage of capitalized letters in a comment. In matrix entry form:\\\n",
    "`[number of swear words in comment, percentage of capitalized letters in a comment]`\\\n",
    "Thus `[0, 0]` would correspond to a comment with zero swear words and zero capitalized letters.\n",
    "\n",
    "\n",
    "### Rubric\n",
    "\n",
    "We will be evaluating this section in part by how clever your choice of features were (and that you were able to extract them).\n",
    "Simple sets of features may not be as informative as complex setds of features, but simple features are easier to extract from a dataset compared to complex features.\n",
    "\n",
    "A breakdown of the marking for this task:\n",
    "* [**10 marks**] basic features gathered (trivial)\n",
    "* [**25 marks**] quality features gathered (advanced), corresponding to unusual features or clever features most would not have considered\n",
    "* [**5 marks**] formatting the features and output correctly so it can be used immediately downstream for the machine learning classifiers without any further preprocessing needing to be done at that stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bcbeb03d-2d9c-462e-946a-6739a051fd6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is 'hat' in the wordlist? True\n",
      "Is 'Hat' in the wordlist? False\n"
     ]
    }
   ],
   "source": [
    "# EXAMPLE CODE: check if a word is in a list of words\n",
    "list_of_words = [\"house\", \"hat\", \"war\"]\n",
    "word = \"hat\"\n",
    "print(\"Is 'hat' in the wordlist?\", word in list_of_words)\n",
    "\n",
    "word = \"Hat\"\n",
    "print(\"Is 'Hat' in the wordlist?\", word in list_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbad27fd-292e-46c7-839f-354ac366919e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is '?' in the characterlist? True\n",
      "Is '\\n' (newline) in the characterlist? True\n"
     ]
    }
   ],
   "source": [
    "# EXAMPLE CODE: check if a character is in a list of characters\n",
    "character_string = '?.\",!@$%^&*()\\n' # using a String as if it were a list\n",
    "character = \"?\"\n",
    "print(\"Is '?' in the characterlist?\", character in character_string)\n",
    "\n",
    "character = \"\\n\"\n",
    "print(\"Is '\\\\n' (newline) in the characterlist?\", character in character_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c35dae9c-6929-4568-8e9e-ce3e1dd750b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE CODE: for more code fragments that may be useful\n",
    "#               check the Discord server (I will not be adding new snippets to this Task here)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2122e537-b8bf-4ffb-8a7b-b4ce3df3a7ad",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "    <h4>WRITE CODE</h4>\n",
    "    In the cell below, write the code that extracts features from the dataset.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "3ea231bf-3fee-486d-a0ac-5414717fd61d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of Non-Toxic coments:  2235\n",
      "Amount of Somewhat Toxic coments:  3640\n",
      "Amount of Toxic coments:  1989\n",
      "Amount of Very Toxic coments:  2136\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE IN THIS CELL\n",
    "from nltk.tokenize import SpaceTokenizer\n",
    "from sklearn import preprocessing\n",
    "import string\n",
    "tk = SpaceTokenizer()\n",
    "\n",
    "# read dataset from file\n",
    "commentDF = pd.read_csv('train.csv')\n",
    "commentDF = commentDF.head(10000)\n",
    "comments = commentDF['comment_text'].tolist()\n",
    "\n",
    "# Prepare list of bad words\n",
    "badWordDF = pd.read_csv('badwords.csv')\n",
    "badwords = badWordDF['Words'].tolist()\n",
    "\n",
    "# Prepare list of negative words\n",
    "negativewords = []\n",
    "with open('negativewords.txt', 'r') as file:\n",
    "    data = file.read().replace('\\n', '')\n",
    "    negativewords = nltk.word_tokenize(data)\n",
    "for i in range(len(negativewords)):\n",
    "    negativewords[i] = negativewords[i].translate(str.maketrans('', '', string.punctuation))\n",
    "while(\"\" in negativewords) :\n",
    "    negativewords.remove(\"\")\n",
    "\n",
    "# Tokenize to words\n",
    "for i in range(len(comments)):\n",
    "    comments[i] = str(comments[i])\n",
    "    comments[i] = comments[i].replace(\"\\n\", \" \")\n",
    "    comments[i] = tk.tokenize(comments[i])\n",
    "\n",
    "# Remove punctuations and white spaces\n",
    "for tokens in comments:\n",
    "    for i in range(len(tokens)):\n",
    "        tokens[i] = tokens[i].strip(\"\\\")(.*,\\' \")\n",
    "        tokens[i] = tokens[i].lower()\n",
    "    while(\"\" in tokens) :\n",
    "        tokens.remove(\"\")\n",
    "\n",
    "# iterate over each data sample in the dataset\n",
    "#     extract features from each data sample\n",
    "\n",
    "# Feature 1\n",
    "X0 = [] # Feature 1: Comment including bad words\n",
    "for comment in comments:\n",
    "    score = 0\n",
    "    for token in comment:\n",
    "        if token in badwords:\n",
    "            score += 1\n",
    "    X0.append(score)\n",
    "\n",
    "# Feature 2\n",
    "X1 = [] # Feature 3: Comment including negative words\n",
    "for comment in comments:\n",
    "    score = 0\n",
    "    for token in comment:\n",
    "        if token in negativewords:\n",
    "            score += 1\n",
    "    X1.append(score)\n",
    "\n",
    "# Feature 3\n",
    "X2 = [] # Feature 3: punctuation is used in the body of a word\n",
    "character_string = '?!@$%^#+():;-_\\\"&*<>{}[]`~|/.,' \n",
    "for comment in comments:\n",
    "    score = 0\n",
    "    for token in comment:\n",
    "        for i in range(len(token)-1):\n",
    "            if token[i] in character_string:\n",
    "                score += 1\n",
    "    X2.append(score)\n",
    "\n",
    "# Feature 4\n",
    "X3 = [] # Feature 3: Amount of exclamation marks\n",
    "for comment in comments:\n",
    "    score = 0\n",
    "    for token in comment:\n",
    "        score += token.count('!')\n",
    "    X3.append(score)\n",
    "\n",
    "# normalize/scale the features and outputs in the range [0-1]\n",
    "#     note that each model may have a different set of requirements as to how it expects its input\n",
    "\n",
    "# Source: https://www.geeksforgeeks.org/how-to-normalize-an-array-in-numpy-in-python/\n",
    "# explicit function to normalize array\n",
    "def normalize(arr, t_min, t_max):\n",
    "    norm_arr = []\n",
    "    diff = t_max - t_min\n",
    "    diff_arr = max(arr) - min(arr)   \n",
    "    for i in arr:\n",
    "        temp = (((i - min(arr))*diff)/diff_arr) + t_min\n",
    "        norm_arr.append(temp)\n",
    "    return norm_arr\n",
    "\n",
    "X0 = normalize(X0, 0, 1)\n",
    "X1 = normalize(X1, 0, 1)\n",
    "X2 = normalize(X2, 0, 1)\n",
    "X3 = normalize(X3, 0, 1)\n",
    "\n",
    "# prepare output values in the correct format\n",
    "# For classification the output will be categories such as [toxic, non_toxic, severe_toxic, ...]\n",
    "#     the classification models want these categories represented as integer values which correspond to the original\n",
    "#     categories, such as [0, 1, 2, ...] where 0=toxic, 1=non_toxic, 2=severe_toxic, ...\n",
    "\n",
    "# 0 = non toxic, 1 = Somewhat toxic, 2 = toxic, 3 = Very toxic\n",
    "\n",
    "ArrX = []\n",
    "ArrY = []\n",
    "\n",
    "for i in range(len(X0)):\n",
    "    ArrX.append([X0[i], X1[i], X2[i], X3[i]])\n",
    "    score = (X0[i] * 10) + (X1[i] * 10) + (X2[i]*5) + (X3[i] * 3)\n",
    "    if score <= 0.01:\n",
    "        ArrY.append(0)\n",
    "        continue\n",
    "    if 0.01 < score <= 0.05:\n",
    "        ArrY.append(1)\n",
    "        continue\n",
    "    if 0.05 <= score <= 0.1:\n",
    "        ArrY.append(2)\n",
    "        continue\n",
    "    if 0.1 <= score:\n",
    "        ArrY.append(3)\n",
    "        continue\n",
    "\n",
    "\n",
    "nonT = 0\n",
    "ST = 0\n",
    "T = 0\n",
    "VT = 0\n",
    "for i in range(len(ArrY)):\n",
    "    if ArrY[i] == 0:\n",
    "        nonT += 1\n",
    "    if ArrY[i] == 1:\n",
    "        ST += 1\n",
    "    if ArrY[i] == 2:\n",
    "        T += 1\n",
    "    if ArrY[i] == 3:\n",
    "        VT += 1\n",
    "print(\"Amount of Non-Toxic coments: \", nonT)\n",
    "print(\"Amount of Somewhat Toxic coments: \", ST)\n",
    "print(\"Amount of Toxic coments: \", T)\n",
    "print(\"Amount of Very Toxic coments: \", VT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b496bf53-1b24-4b5f-a9da-cc23b8f74a00",
   "metadata": {},
   "source": [
    "----\n",
    "<div class=\"alert alert-info\">\n",
    "    <h4>PRO TIP</h4>\n",
    "    Classifiers take two arrays as input: <strong>array X</strong> and <strong>array y</strong>.</br>\n",
    "    <strong>array X</strong> has shape <tt>(number_of_samples, number_of_features)</tt> containing the training samples feature data</br>\n",
    "    <strong>array y</strong> of class labels/outputs (strings or integers) has shape <tt>(number_of_samples)</tt></p>\n",
    "    <p></p>\n",
    "    <p style=\"text-indent:0px\"><tt>print(photos.shape, labels.shape)</br>\n",
    "    num_samples = labels.shape[0]<br>\n",
    "    x = np.reshape(photos, (num_samples, -1))<tt></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6362c59e-1ddc-496a-9024-ba06b2bb177b",
   "metadata": {},
   "source": [
    "## Task: Decision Tree   (5 Marks)\n",
    "\n",
    "Build a *decision tree* model to identify toxic comments.\n",
    "\n",
    "From Norvig & Russel's \"*AI: A Modern Approach*\" (pg. 707, 3rd ed.):\n",
    "> In many areas of industry and commerce, decision trees are usually the first method tried when a classification method is to be extracted from a data set. One important property of decision trees is that it is possible for a human to understand the reason for the output of the learning algorithm. (Indeed, this is a legal requirement for financial decisions that are subject to anti-discrimination laws.) This is a property not shared by some other representations, such as neural networks.\n",
    "\n",
    "From https://scikit-learn.org/stable/modules/tree.html:\n",
    "> `DecisionTreeClassifier` is capable of both:\n",
    "> * **binary classification** where the labels are `[-1, 1]`\n",
    "> * **multiclass classification** where the labels are `[0, ..., K-1]`\n",
    "\n",
    "\n",
    "### Type Of Task We Are Working With\n",
    "\n",
    "Note our task isn't a **classification** task (i.e., predicting a *discrete* value) but a **regression** task (i.e., predicting a *continuous* value). We could pursue one of two approaches:\n",
    "* keep the task as a regression task and use regression versions for each model (e.g., *decision tree regression*, *SVM for regression*, *neural network for regression*, etc.)\n",
    "* convert the regression task into a classification task where we are predicting a range of values rather than a specific value (i.e., discretizing the output space)\n",
    "\n",
    "To discretize the output we are predicting (i.e., convert a continuous value into a set of points/classes/categories), instead of predicting the temperature from 0 degrees Fahrenheit to 100 degrees Fahrenheit, we predict a temperature range:\n",
    "* **freezing** (0 degrees to 20 degrees Fahrenheit)\n",
    "* **cold** (20 degrees to 40 degrees Fahrenheit)\n",
    "* **moderate** (40 degrees to 60 degrees Fahrenheit)\n",
    "* **warm** (60 degrees to 80 degrees Fahrenheit)\n",
    "* **hot** (80 degrees to 100 degrees Fahrenheit)\n",
    "\n",
    "which transforms the regression problem into a 5-class classification task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95089c7a-f618-4671-8e57-9a477f56a315",
   "metadata": {},
   "source": [
    "### Decision Trees For Classification\n",
    "\n",
    "Example code for a **Decision Tree** performing classification. The **Decision Tree** model is predicting one category from a set of categories, such as which genre a film belongs to (`Horror`, `Comedy`, `Action`, etc.):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f16d4f7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# EXAMPLE CODE: COMMENT OUT THIS CODE CELL AFTER IMPLEMENTING YOUR CODE BELOW\\nfrom sklearn import tree\\n\\nX = [[0, 0, -1], [1, 1, 1], [1, 10, 9], [-3, 0, 33]]\\nY = [0, 1, 4, 1]\\n\\n# DecisionTreeClassifier takes as input two arrays: X & Y\\n#    an array X, sparse or dense, of shape (number_of_samples, number_of_features) holding the training samples\\n#    and an array Y of integer values, of shape (number_of_samples) holding the class labels for the training samples\\nclf = tree.DecisionTreeClassifier()\\n\\n# train the decision tree classifier model\\nclf = clf.fit(X, Y)\\n\\n# after being fitted, predict from a new set of samples\\nclf.predict([[2., 2., 10.]])\\n\\n\\n# plot a visualization of the decision tree\\ntree.plot_tree(clf)\\n\\n\\n# a text visualization of the decision tree\\nfrom sklearn.tree import export_text\\ntext_tree = export_text(clf, feature_names=[\"First Feature\", \"Height Feature\", \"Salary Feature\"])\\nprint(\"Text visualization of decision tree:\\n\", text_tree)\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# EXAMPLE CODE: COMMENT OUT THIS CODE CELL AFTER IMPLEMENTING YOUR CODE BELOW\n",
    "from sklearn import tree\n",
    "\n",
    "X = [[0, 0, -1], [1, 1, 1], [1, 10, 9], [-3, 0, 33]]\n",
    "Y = [0, 1, 4, 1]\n",
    "\n",
    "# DecisionTreeClassifier takes as input two arrays: X & Y\n",
    "#    an array X, sparse or dense, of shape (number_of_samples, number_of_features) holding the training samples\n",
    "#    and an array Y of integer values, of shape (number_of_samples) holding the class labels for the training samples\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "\n",
    "# train the decision tree classifier model\n",
    "clf = clf.fit(X, Y)\n",
    "\n",
    "# after being fitted, predict from a new set of samples\n",
    "clf.predict([[2., 2., 10.]])\n",
    "\n",
    "\n",
    "# plot a visualization of the decision tree\n",
    "tree.plot_tree(clf)\n",
    "\n",
    "\n",
    "# a text visualization of the decision tree\n",
    "from sklearn.tree import export_text\n",
    "text_tree = export_text(clf, feature_names=[\"First Feature\", \"Height Feature\", \"Salary Feature\"])\n",
    "print(\"Text visualization of decision tree:\\n\", text_tree)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df590be3-a107-4399-b79e-ebfca3b6cf15",
   "metadata": {},
   "source": [
    "### Decision Trees For Regression\n",
    "\n",
    "Regression using **Decision Trees** is [found here](https://scikit-learn.org/stable/modules/tree.html#regression).\n",
    "\n",
    "Example code of a **Decision Tree** for regression (where the **Decision Tree** model is predicting a continuous value):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "94a8a959",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# EXAMPLE CODE: COMMENT OUT THIS CODE CELL AFTER IMPLEMENTING YOUR CODE BELOW\\n# code from https://scikit-learn.org/stable/modules/tree.html#regression\\n\\nfrom sklearn import tree\\n\\nX = [[0, 0], [2, 2]]\\ny = [0.5, 2.5]\\n\\n\\nclf = tree.DecisionTreeRegressor()\\n\\n# train the decision tree regression model\\nclf = clf.fit(X, y)\\n\\n# after being fitted, predict from a new set of samples\\nclf.predict([[1, 1]])\\n\\n# plot a visualization of the decision tree\\ntree.plot_tree(clf)\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# EXAMPLE CODE: COMMENT OUT THIS CODE CELL AFTER IMPLEMENTING YOUR CODE BELOW\n",
    "# code from https://scikit-learn.org/stable/modules/tree.html#regression\n",
    "\n",
    "from sklearn import tree\n",
    "\n",
    "X = [[0, 0], [2, 2]]\n",
    "y = [0.5, 2.5]\n",
    "\n",
    "\n",
    "clf = tree.DecisionTreeRegressor()\n",
    "\n",
    "# train the decision tree regression model\n",
    "clf = clf.fit(X, y)\n",
    "\n",
    "# after being fitted, predict from a new set of samples\n",
    "clf.predict([[1, 1]])\n",
    "\n",
    "# plot a visualization of the decision tree\n",
    "tree.plot_tree(clf)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1689ef-d3d7-443f-844e-abb627da153f",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "    <h4>WRITE CODE</h4>\n",
    "    In the cell below, write the code that implements a Decision Tree classifier.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b54a755e-41ef-4a0d-b0fc-85666a37febc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(195.01156015037594, 208.38, 'X[2] <= 0.005\\nmse = 1.115\\nsamples = 10000\\nvalue = 1.403'),\n",
       " Text(117.1328007518797, 190.26, 'X[1] <= 0.005\\nmse = 0.699\\nsamples = 6627\\nvalue = 0.916'),\n",
       " Text(64.3483082706767, 172.14, 'X[1] <= 0.001\\nmse = 0.362\\nsamples = 5685\\nvalue = 0.673'),\n",
       " Text(27.0609022556391, 154.01999999999998, 'X[2] <= 0.002\\nmse = 0.247\\nsamples = 3301\\nvalue = 0.332'),\n",
       " Text(13.845112781954889, 135.89999999999998, 'X[0] <= 0.001\\nmse = 0.128\\nsamples = 2493\\nvalue = 0.113'),\n",
       " Text(5.034586466165414, 117.77999999999999, 'X[3] <= 0.005\\nmse = 0.032\\nsamples = 2295\\nvalue = 0.028'),\n",
       " Text(2.517293233082707, 99.66, 'mse = 0.0\\nsamples = 2235\\nvalue = 0.0'),\n",
       " Text(7.55187969924812, 99.66, 'X[3] <= 0.09\\nmse = 0.129\\nsamples = 60\\nvalue = 1.067'),\n",
       " Text(5.034586466165414, 81.53999999999999, 'mse = 0.0\\nsamples = 58\\nvalue = 1.0'),\n",
       " Text(10.069172932330828, 81.53999999999999, 'mse = 0.0\\nsamples = 2\\nvalue = 3.0'),\n",
       " Text(22.655639097744363, 117.77999999999999, 'X[0] <= 0.005\\nmse = 0.172\\nsamples = 198\\nvalue = 1.101'),\n",
       " Text(17.621052631578948, 99.66, 'X[3] <= 0.011\\nmse = 0.005\\nsamples = 187\\nvalue = 1.005'),\n",
       " Text(15.10375939849624, 81.53999999999999, 'mse = 0.0\\nsamples = 186\\nvalue = 1.0'),\n",
       " Text(20.138345864661655, 81.53999999999999, 'mse = 0.0\\nsamples = 1\\nvalue = 2.0'),\n",
       " Text(27.690225563909777, 99.66, 'X[0] <= 0.01\\nmse = 0.198\\nsamples = 11\\nvalue = 2.727'),\n",
       " Text(25.17293233082707, 81.53999999999999, 'X[3] <= 0.005\\nmse = 0.188\\nsamples = 4\\nvalue = 2.25'),\n",
       " Text(22.655639097744363, 63.41999999999999, 'mse = 0.0\\nsamples = 3\\nvalue = 2.0'),\n",
       " Text(27.690225563909777, 63.41999999999999, 'mse = 0.0\\nsamples = 1\\nvalue = 3.0'),\n",
       " Text(30.20751879699248, 81.53999999999999, 'mse = 0.0\\nsamples = 7\\nvalue = 3.0'),\n",
       " Text(40.27669172932331, 135.89999999999998, 'X[0] <= 0.003\\nmse = 0.011\\nsamples = 808\\nvalue = 1.009'),\n",
       " Text(35.242105263157896, 117.77999999999999, 'X[3] <= 0.011\\nmse = 0.001\\nsamples = 803\\nvalue = 1.001'),\n",
       " Text(32.72481203007519, 99.66, 'mse = 0.0\\nsamples = 802\\nvalue = 1.0'),\n",
       " Text(37.75939849624061, 99.66, 'mse = 0.0\\nsamples = 1\\nvalue = 2.0'),\n",
       " Text(45.311278195488725, 117.77999999999999, 'X[0] <= 0.035\\nmse = 0.16\\nsamples = 5\\nvalue = 2.2'),\n",
       " Text(42.793984962406014, 99.66, 'mse = 0.0\\nsamples = 4\\nvalue = 2.0'),\n",
       " Text(47.82857142857143, 99.66, 'mse = 0.0\\nsamples = 1\\nvalue = 3.0'),\n",
       " Text(101.63571428571429, 154.01999999999998, 'X[0] <= 0.002\\nmse = 0.138\\nsamples = 2384\\nvalue = 1.146'),\n",
       " Text(81.18270676691729, 135.89999999999998, 'X[2] <= 0.002\\nmse = 0.097\\nsamples = 2251\\nvalue = 1.105'),\n",
       " Text(64.19097744360903, 117.77999999999999, 'X[3] <= 0.005\\nmse = 0.018\\nsamples = 1677\\nvalue = 1.016'),\n",
       " Text(52.863157894736844, 99.66, 'X[3] <= 0.002\\nmse = 0.004\\nsamples = 1641\\nvalue = 1.004'),\n",
       " Text(50.34586466165414, 81.53999999999999, 'mse = 0.0\\nsamples = 1519\\nvalue = 1.0'),\n",
       " Text(55.380451127819555, 81.53999999999999, 'X[0] <= 0.001\\nmse = 0.047\\nsamples = 122\\nvalue = 1.049'),\n",
       " Text(52.863157894736844, 63.41999999999999, 'mse = 0.0\\nsamples = 109\\nvalue = 1.0'),\n",
       " Text(57.89774436090226, 63.41999999999999, 'X[1] <= 0.003\\nmse = 0.249\\nsamples = 13\\nvalue = 1.462'),\n",
       " Text(55.380451127819555, 45.29999999999998, 'mse = 0.0\\nsamples = 7\\nvalue = 1.0'),\n",
       " Text(60.41503759398496, 45.29999999999998, 'mse = 0.0\\nsamples = 6\\nvalue = 2.0'),\n",
       " Text(75.51879699248121, 99.66, 'X[1] <= 0.003\\nmse = 0.354\\nsamples = 36\\nvalue = 1.583'),\n",
       " Text(70.48421052631579, 81.53999999999999, 'X[0] <= 0.001\\nmse = 0.193\\nsamples = 23\\nvalue = 1.261'),\n",
       " Text(67.96691729323308, 63.41999999999999, 'X[3] <= 0.011\\nmse = 0.128\\nsamples = 20\\nvalue = 1.15'),\n",
       " Text(65.44962406015038, 45.29999999999998, 'mse = 0.0\\nsamples = 17\\nvalue = 1.0'),\n",
       " Text(70.48421052631579, 45.29999999999998, 'mse = 0.0\\nsamples = 3\\nvalue = 2.0'),\n",
       " Text(73.0015037593985, 63.41999999999999, 'mse = 0.0\\nsamples = 3\\nvalue = 2.0'),\n",
       " Text(80.55338345864662, 81.53999999999999, 'X[3] <= 0.015\\nmse = 0.13\\nsamples = 13\\nvalue = 2.154'),\n",
       " Text(78.03609022556391, 63.41999999999999, 'mse = 0.0\\nsamples = 11\\nvalue = 2.0'),\n",
       " Text(83.07067669172933, 63.41999999999999, 'mse = 0.0\\nsamples = 2\\nvalue = 3.0'),\n",
       " Text(98.17443609022557, 117.77999999999999, 'X[1] <= 0.003\\nmse = 0.235\\nsamples = 574\\nvalue = 1.366'),\n",
       " Text(93.13984962406016, 99.66, 'X[3] <= 0.005\\nmse = 0.031\\nsamples = 377\\nvalue = 1.032'),\n",
       " Text(90.62255639097745, 81.53999999999999, 'X[0] <= 0.001\\nmse = 0.003\\nsamples = 366\\nvalue = 1.003'),\n",
       " Text(88.10526315789474, 63.41999999999999, 'mse = 0.0\\nsamples = 343\\nvalue = 1.0'),\n",
       " Text(93.13984962406016, 63.41999999999999, 'X[3] <= 0.002\\nmse = 0.042\\nsamples = 23\\nvalue = 1.043'),\n",
       " Text(90.62255639097745, 45.29999999999998, 'mse = 0.0\\nsamples = 22\\nvalue = 1.0'),\n",
       " Text(95.65714285714286, 45.29999999999998, 'mse = 0.0\\nsamples = 1\\nvalue = 2.0'),\n",
       " Text(95.65714285714286, 81.53999999999999, 'mse = 0.0\\nsamples = 11\\nvalue = 2.0'),\n",
       " Text(103.20902255639098, 99.66, 'X[3] <= 0.013\\nmse = 0.005\\nsamples = 197\\nvalue = 2.005'),\n",
       " Text(100.69172932330828, 81.53999999999999, 'mse = 0.0\\nsamples = 196\\nvalue = 2.0'),\n",
       " Text(105.72631578947369, 81.53999999999999, 'mse = 0.0\\nsamples = 1\\nvalue = 3.0'),\n",
       " Text(122.08872180451128, 135.89999999999998, 'X[0] <= 0.003\\nmse = 0.339\\nsamples = 133\\nvalue = 1.827'),\n",
       " Text(115.79548872180452, 117.77999999999999, 'X[1] <= 0.003\\nmse = 0.247\\nsamples = 81\\nvalue = 1.556'),\n",
       " Text(113.2781954887218, 99.66, 'X[3] <= 0.002\\nmse = 0.195\\nsamples = 49\\nvalue = 1.265'),\n",
       " Text(110.76090225563911, 81.53999999999999, 'X[2] <= 0.002\\nmse = 0.05\\nsamples = 38\\nvalue = 1.053'),\n",
       " Text(108.2436090225564, 63.41999999999999, 'mse = 0.0\\nsamples = 36\\nvalue = 1.0'),\n",
       " Text(113.2781954887218, 63.41999999999999, 'mse = 0.0\\nsamples = 2\\nvalue = 2.0'),\n",
       " Text(115.79548872180452, 81.53999999999999, 'mse = 0.0\\nsamples = 11\\nvalue = 2.0'),\n",
       " Text(118.31278195488723, 99.66, 'mse = 0.0\\nsamples = 32\\nvalue = 2.0'),\n",
       " Text(128.38195488721806, 117.77999999999999, 'X[0] <= 0.007\\nmse = 0.188\\nsamples = 52\\nvalue = 2.25'),\n",
       " Text(123.34736842105264, 99.66, 'X[3] <= 0.005\\nmse = 0.103\\nsamples = 43\\nvalue = 2.116'),\n",
       " Text(120.83007518796992, 81.53999999999999, 'X[3] <= 0.002\\nmse = 0.025\\nsamples = 39\\nvalue = 2.026'),\n",
       " Text(118.31278195488723, 63.41999999999999, 'mse = 0.0\\nsamples = 34\\nvalue = 2.0'),\n",
       " Text(123.34736842105264, 63.41999999999999, 'X[0] <= 0.004\\nmse = 0.16\\nsamples = 5\\nvalue = 2.2'),\n",
       " Text(120.83007518796992, 45.29999999999998, 'mse = 0.0\\nsamples = 4\\nvalue = 2.0'),\n",
       " Text(125.86466165413535, 45.29999999999998, 'mse = 0.0\\nsamples = 1\\nvalue = 3.0'),\n",
       " Text(125.86466165413535, 81.53999999999999, 'mse = 0.0\\nsamples = 4\\nvalue = 3.0'),\n",
       " Text(133.41654135338348, 99.66, 'X[0] <= 0.008\\nmse = 0.099\\nsamples = 9\\nvalue = 2.889'),\n",
       " Text(130.89924812030077, 81.53999999999999, 'X[1] <= 0.003\\nmse = 0.222\\nsamples = 3\\nvalue = 2.667'),\n",
       " Text(128.38195488721806, 63.41999999999999, 'mse = 0.0\\nsamples = 1\\nvalue = 2.0'),\n",
       " Text(133.41654135338348, 63.41999999999999, 'mse = 0.0\\nsamples = 2\\nvalue = 3.0'),\n",
       " Text(135.93383458646616, 81.53999999999999, 'mse = 0.0\\nsamples = 6\\nvalue = 3.0'),\n",
       " Text(169.91729323308272, 172.14, 'X[1] <= 0.008\\nmse = 0.235\\nsamples = 942\\nvalue = 2.379'),\n",
       " Text(158.58947368421053, 154.01999999999998, 'X[0] <= 0.003\\nmse = 0.065\\nsamples = 576\\nvalue = 2.069'),\n",
       " Text(148.52030075187972, 135.89999999999998, 'X[3] <= 0.005\\nmse = 0.033\\nsamples = 550\\nvalue = 2.035'),\n",
       " Text(140.96842105263158, 117.77999999999999, 'X[0] <= 0.001\\nmse = 0.024\\nsamples = 536\\nvalue = 2.024'),\n",
       " Text(138.45112781954887, 99.66, 'mse = 0.0\\nsamples = 438\\nvalue = 2.0'),\n",
       " Text(143.4857142857143, 99.66, 'X[2] <= 0.002\\nmse = 0.115\\nsamples = 98\\nvalue = 2.133'),\n",
       " Text(140.96842105263158, 81.53999999999999, 'mse = 0.0\\nsamples = 67\\nvalue = 2.0'),\n",
       " Text(146.003007518797, 81.53999999999999, 'X[1] <= 0.007\\nmse = 0.243\\nsamples = 31\\nvalue = 2.419'),\n",
       " Text(143.4857142857143, 63.41999999999999, 'mse = 0.0\\nsamples = 18\\nvalue = 2.0'),\n",
       " Text(148.52030075187972, 63.41999999999999, 'mse = 0.0\\nsamples = 13\\nvalue = 3.0'),\n",
       " Text(156.07218045112782, 117.77999999999999, 'X[1] <= 0.007\\nmse = 0.245\\nsamples = 14\\nvalue = 2.429'),\n",
       " Text(153.5548872180451, 99.66, 'X[0] <= 0.002\\nmse = 0.099\\nsamples = 9\\nvalue = 2.111'),\n",
       " Text(151.03759398496243, 81.53999999999999, 'mse = 0.0\\nsamples = 7\\nvalue = 2.0'),\n",
       " Text(156.07218045112782, 81.53999999999999, 'X[2] <= 0.002\\nmse = 0.25\\nsamples = 2\\nvalue = 2.5'),\n",
       " Text(153.5548872180451, 63.41999999999999, 'mse = 0.0\\nsamples = 1\\nvalue = 2.0'),\n",
       " Text(158.58947368421053, 63.41999999999999, 'mse = 0.0\\nsamples = 1\\nvalue = 3.0'),\n",
       " Text(158.58947368421053, 99.66, 'mse = 0.0\\nsamples = 5\\nvalue = 3.0'),\n",
       " Text(168.65864661654138, 135.89999999999998, 'X[0] <= 0.004\\nmse = 0.155\\nsamples = 26\\nvalue = 2.808'),\n",
       " Text(166.14135338345866, 117.77999999999999, 'X[1] <= 0.007\\nmse = 0.25\\nsamples = 10\\nvalue = 2.5'),\n",
       " Text(163.62406015037595, 99.66, 'X[3] <= 0.002\\nmse = 0.204\\nsamples = 7\\nvalue = 2.286'),\n",
       " Text(161.10676691729324, 81.53999999999999, 'mse = 0.0\\nsamples = 5\\nvalue = 2.0'),\n",
       " Text(166.14135338345866, 81.53999999999999, 'mse = 0.0\\nsamples = 2\\nvalue = 3.0'),\n",
       " Text(168.65864661654138, 99.66, 'mse = 0.0\\nsamples = 3\\nvalue = 3.0'),\n",
       " Text(171.17593984962406, 117.77999999999999, 'mse = 0.0\\nsamples = 16\\nvalue = 3.0'),\n",
       " Text(181.2451127819549, 154.01999999999998, 'X[1] <= 0.01\\nmse = 0.116\\nsamples = 366\\nvalue = 2.866'),\n",
       " Text(178.7278195488722, 135.89999999999998, 'X[2] <= 0.002\\nmse = 0.236\\nsamples = 128\\nvalue = 2.617'),\n",
       " Text(176.21052631578948, 117.77999999999999, 'X[0] <= 0.001\\nmse = 0.243\\nsamples = 84\\nvalue = 2.417'),\n",
       " Text(173.69323308270677, 99.66, 'X[3] <= 0.002\\nmse = 0.097\\nsamples = 55\\nvalue = 2.109'),\n",
       " Text(171.17593984962406, 81.53999999999999, 'mse = 0.0\\nsamples = 49\\nvalue = 2.0'),\n",
       " Text(176.21052631578948, 81.53999999999999, 'mse = 0.0\\nsamples = 6\\nvalue = 3.0'),\n",
       " Text(178.7278195488722, 99.66, 'mse = 0.0\\nsamples = 29\\nvalue = 3.0'),\n",
       " Text(181.2451127819549, 117.77999999999999, 'mse = 0.0\\nsamples = 44\\nvalue = 3.0'),\n",
       " Text(183.7624060150376, 135.89999999999998, 'mse = 0.0\\nsamples = 238\\nvalue = 3.0'),\n",
       " Text(272.8903195488722, 190.26, 'X[2] <= 0.011\\nmse = 0.551\\nsamples = 3373\\nvalue = 2.359'),\n",
       " Text(228.28703007518797, 172.14, 'X[1] <= 0.001\\nmse = 0.556\\nsamples = 1561\\nvalue = 1.878'),\n",
       " Text(197.60751879699248, 154.01999999999998, 'X[3] <= 0.002\\nmse = 0.133\\nsamples = 633\\nvalue = 1.148'),\n",
       " Text(188.796992481203, 135.89999999999998, 'X[0] <= 0.001\\nmse = 0.041\\nsamples = 532\\nvalue = 1.043'),\n",
       " Text(186.27969924812032, 117.77999999999999, 'mse = 0.0\\nsamples = 503\\nvalue = 1.0'),\n",
       " Text(191.31428571428572, 117.77999999999999, 'X[2] <= 0.008\\nmse = 0.164\\nsamples = 29\\nvalue = 1.793'),\n",
       " Text(188.796992481203, 99.66, 'X[0] <= 0.002\\nmse = 0.222\\nsamples = 9\\nvalue = 1.333'),\n",
       " Text(186.27969924812032, 81.53999999999999, 'mse = 0.0\\nsamples = 6\\nvalue = 1.0'),\n",
       " Text(191.31428571428572, 81.53999999999999, 'mse = 0.0\\nsamples = 3\\nvalue = 2.0'),\n",
       " Text(193.83157894736843, 99.66, 'mse = 0.0\\nsamples = 20\\nvalue = 2.0'),\n",
       " Text(206.41804511278195, 135.89999999999998, 'X[2] <= 0.008\\nmse = 0.248\\nsamples = 101\\nvalue = 1.703'),\n",
       " Text(201.38345864661656, 117.77999999999999, 'X[3] <= 0.005\\nmse = 0.234\\nsamples = 51\\nvalue = 1.373'),\n",
       " Text(198.86616541353385, 99.66, 'mse = 0.0\\nsamples = 32\\nvalue = 1.0'),\n",
       " Text(203.90075187969927, 99.66, 'mse = 0.0\\nsamples = 19\\nvalue = 2.0'),\n",
       " Text(211.45263157894738, 117.77999999999999, 'X[3] <= 0.02\\nmse = 0.038\\nsamples = 50\\nvalue = 2.04'),\n",
       " Text(208.93533834586466, 99.66, 'X[0] <= 0.004\\nmse = 0.02\\nsamples = 49\\nvalue = 2.02'),\n",
       " Text(206.41804511278195, 81.53999999999999, 'mse = 0.0\\nsamples = 48\\nvalue = 2.0'),\n",
       " Text(211.45263157894738, 81.53999999999999, 'mse = 0.0\\nsamples = 1\\nvalue = 3.0'),\n",
       " Text(213.9699248120301, 99.66, 'mse = 0.0\\nsamples = 1\\nvalue = 3.0'),\n",
       " Text(258.9665413533835, 154.01999999999998, 'X[1] <= 0.005\\nmse = 0.234\\nsamples = 928\\nvalue = 2.375'),\n",
       " Text(241.03082706766918, 135.89999999999998, 'X[3] <= 0.008\\nmse = 0.061\\nsamples = 569\\nvalue = 2.065'),\n",
       " Text(227.81503759398498, 117.77999999999999, 'X[0] <= 0.002\\nmse = 0.029\\nsamples = 542\\nvalue = 2.03'),\n",
       " Text(219.0045112781955, 99.66, 'X[3] <= 0.002\\nmse = 0.009\\nsamples = 523\\nvalue = 2.01'),\n",
       " Text(216.4872180451128, 81.53999999999999, 'mse = 0.0\\nsamples = 457\\nvalue = 2.0'),\n",
       " Text(221.52180451127822, 81.53999999999999, 'X[0] <= 0.001\\nmse = 0.07\\nsamples = 66\\nvalue = 2.076'),\n",
       " Text(216.4872180451128, 63.41999999999999, 'X[3] <= 0.005\\nmse = 0.033\\nsamples = 58\\nvalue = 2.034'),\n",
       " Text(213.9699248120301, 45.29999999999998, 'mse = 0.0\\nsamples = 39\\nvalue = 2.0'),\n",
       " Text(219.0045112781955, 45.29999999999998, 'X[1] <= 0.003\\nmse = 0.094\\nsamples = 19\\nvalue = 2.105'),\n",
       " Text(216.4872180451128, 27.17999999999998, 'mse = 0.0\\nsamples = 14\\nvalue = 2.0'),\n",
       " Text(221.52180451127822, 27.17999999999998, 'X[2] <= 0.008\\nmse = 0.24\\nsamples = 5\\nvalue = 2.4'),\n",
       " Text(219.0045112781955, 9.059999999999974, 'mse = 0.0\\nsamples = 3\\nvalue = 2.0'),\n",
       " Text(224.0390977443609, 9.059999999999974, 'mse = 0.0\\nsamples = 2\\nvalue = 3.0'),\n",
       " Text(226.5563909774436, 63.41999999999999, 'X[1] <= 0.003\\nmse = 0.234\\nsamples = 8\\nvalue = 2.375'),\n",
       " Text(224.0390977443609, 45.29999999999998, 'mse = 0.0\\nsamples = 5\\nvalue = 2.0'),\n",
       " Text(229.07368421052632, 45.29999999999998, 'mse = 0.0\\nsamples = 3\\nvalue = 3.0'),\n",
       " Text(236.62556390977446, 99.66, 'X[0] <= 0.003\\nmse = 0.244\\nsamples = 19\\nvalue = 2.579'),\n",
       " Text(234.10827067669175, 81.53999999999999, 'X[1] <= 0.003\\nmse = 0.237\\nsamples = 13\\nvalue = 2.385'),\n",
       " Text(231.59097744360903, 63.41999999999999, 'mse = 0.0\\nsamples = 6\\nvalue = 2.0'),\n",
       " Text(236.62556390977446, 63.41999999999999, 'X[2] <= 0.008\\nmse = 0.204\\nsamples = 7\\nvalue = 2.714'),\n",
       " Text(234.10827067669175, 45.29999999999998, 'mse = 0.0\\nsamples = 2\\nvalue = 2.0'),\n",
       " Text(239.14285714285717, 45.29999999999998, 'mse = 0.0\\nsamples = 5\\nvalue = 3.0'),\n",
       " Text(239.14285714285717, 81.53999999999999, 'mse = 0.0\\nsamples = 6\\nvalue = 3.0'),\n",
       " Text(254.2466165413534, 117.77999999999999, 'X[2] <= 0.008\\nmse = 0.173\\nsamples = 27\\nvalue = 2.778'),\n",
       " Text(246.69473684210527, 99.66, 'X[0] <= 0.001\\nmse = 0.243\\nsamples = 12\\nvalue = 2.583'),\n",
       " Text(244.17744360902256, 81.53999999999999, 'X[1] <= 0.003\\nmse = 0.204\\nsamples = 7\\nvalue = 2.286'),\n",
       " Text(241.66015037593985, 63.41999999999999, 'mse = 0.0\\nsamples = 4\\nvalue = 2.0'),\n",
       " Text(246.69473684210527, 63.41999999999999, 'X[3] <= 0.011\\nmse = 0.222\\nsamples = 3\\nvalue = 2.667'),\n",
       " Text(244.17744360902256, 45.29999999999998, 'mse = 0.0\\nsamples = 1\\nvalue = 2.0'),\n",
       " Text(249.21203007518798, 45.29999999999998, 'mse = 0.0\\nsamples = 2\\nvalue = 3.0'),\n",
       " Text(249.21203007518798, 81.53999999999999, 'mse = 0.0\\nsamples = 5\\nvalue = 3.0'),\n",
       " Text(261.79849624060154, 99.66, 'X[3] <= 0.011\\nmse = 0.062\\nsamples = 15\\nvalue = 2.933'),\n",
       " Text(259.2812030075188, 81.53999999999999, 'X[1] <= 0.003\\nmse = 0.222\\nsamples = 3\\nvalue = 2.667'),\n",
       " Text(256.7639097744361, 63.41999999999999, 'X[0] <= 0.001\\nmse = 0.25\\nsamples = 2\\nvalue = 2.5'),\n",
       " Text(254.2466165413534, 45.29999999999998, 'mse = 0.0\\nsamples = 1\\nvalue = 2.0'),\n",
       " Text(259.2812030075188, 45.29999999999998, 'mse = 0.0\\nsamples = 1\\nvalue = 3.0'),\n",
       " Text(261.79849624060154, 63.41999999999999, 'mse = 0.0\\nsamples = 1\\nvalue = 3.0'),\n",
       " Text(264.3157894736842, 81.53999999999999, 'mse = 0.0\\nsamples = 12\\nvalue = 3.0'),\n",
       " Text(276.90225563909775, 135.89999999999998, 'X[1] <= 0.007\\nmse = 0.116\\nsamples = 359\\nvalue = 2.866'),\n",
       " Text(274.38496240601506, 117.77999999999999, 'X[2] <= 0.008\\nmse = 0.247\\nsamples = 108\\nvalue = 2.556'),\n",
       " Text(271.8676691729323, 99.66, 'X[3] <= 0.005\\nmse = 0.099\\nsamples = 54\\nvalue = 2.111'),\n",
       " Text(269.35037593984964, 81.53999999999999, 'X[0] <= 0.002\\nmse = 0.038\\nsamples = 50\\nvalue = 2.04'),\n",
       " Text(266.83308270676696, 63.41999999999999, 'mse = 0.0\\nsamples = 48\\nvalue = 2.0'),\n",
       " Text(271.8676691729323, 63.41999999999999, 'mse = 0.0\\nsamples = 2\\nvalue = 3.0'),\n",
       " Text(274.38496240601506, 81.53999999999999, 'mse = 0.0\\nsamples = 4\\nvalue = 3.0'),\n",
       " Text(276.90225563909775, 99.66, 'mse = 0.0\\nsamples = 54\\nvalue = 3.0'),\n",
       " Text(279.4195488721805, 117.77999999999999, 'mse = 0.0\\nsamples = 251\\nvalue = 3.0'),\n",
       " Text(317.4936090225564, 172.14, 'X[2] <= 0.017\\nmse = 0.175\\nsamples = 1812\\nvalue = 2.774'),\n",
       " Text(305.2218045112782, 154.01999999999998, 'X[1] <= 0.003\\nmse = 0.249\\nsamples = 703\\nvalue = 2.474'),\n",
       " Text(302.7045112781955, 135.89999999999998, 'X[3] <= 0.008\\nmse = 0.077\\nsamples = 404\\nvalue = 2.084'),\n",
       " Text(290.74736842105267, 117.77999999999999, 'X[0] <= 0.001\\nmse = 0.033\\nsamples = 380\\nvalue = 2.034'),\n",
       " Text(281.93684210526317, 99.66, 'X[3] <= 0.002\\nmse = 0.011\\nsamples = 358\\nvalue = 2.011'),\n",
       " Text(279.4195488721805, 81.53999999999999, 'mse = 0.0\\nsamples = 320\\nvalue = 2.0'),\n",
       " Text(284.4541353383459, 81.53999999999999, 'X[1] <= 0.001\\nmse = 0.094\\nsamples = 38\\nvalue = 2.105'),\n",
       " Text(281.93684210526317, 63.41999999999999, 'mse = 0.0\\nsamples = 31\\nvalue = 2.0'),\n",
       " Text(286.9714285714286, 63.41999999999999, 'X[2] <= 0.014\\nmse = 0.245\\nsamples = 7\\nvalue = 2.571'),\n",
       " Text(284.4541353383459, 45.29999999999998, 'X[3] <= 0.005\\nmse = 0.188\\nsamples = 4\\nvalue = 2.25'),\n",
       " Text(281.93684210526317, 27.17999999999998, 'mse = 0.0\\nsamples = 3\\nvalue = 2.0'),\n",
       " Text(286.9714285714286, 27.17999999999998, 'mse = 0.0\\nsamples = 1\\nvalue = 3.0'),\n",
       " Text(289.4887218045113, 45.29999999999998, 'mse = 0.0\\nsamples = 3\\nvalue = 3.0'),\n",
       " Text(299.5578947368421, 99.66, 'X[1] <= 0.001\\nmse = 0.242\\nsamples = 22\\nvalue = 2.409'),\n",
       " Text(294.5233082706767, 81.53999999999999, 'X[0] <= 0.004\\nmse = 0.09\\nsamples = 10\\nvalue = 2.1'),\n",
       " Text(292.006015037594, 63.41999999999999, 'mse = 0.0\\nsamples = 9\\nvalue = 2.0'),\n",
       " Text(297.04060150375943, 63.41999999999999, 'mse = 0.0\\nsamples = 1\\nvalue = 3.0'),\n",
       " Text(304.59248120300754, 81.53999999999999, 'X[2] <= 0.014\\nmse = 0.222\\nsamples = 12\\nvalue = 2.667'),\n",
       " Text(302.07518796992485, 63.41999999999999, 'X[0] <= 0.002\\nmse = 0.245\\nsamples = 7\\nvalue = 2.429'),\n",
       " Text(299.5578947368421, 45.29999999999998, 'X[3] <= 0.003\\nmse = 0.16\\nsamples = 5\\nvalue = 2.2'),\n",
       " Text(297.04060150375943, 27.17999999999998, 'mse = 0.0\\nsamples = 4\\nvalue = 2.0'),\n",
       " Text(302.07518796992485, 27.17999999999998, 'mse = 0.0\\nsamples = 1\\nvalue = 3.0'),\n",
       " Text(304.59248120300754, 45.29999999999998, 'mse = 0.0\\nsamples = 2\\nvalue = 3.0'),\n",
       " Text(307.1097744360902, 63.41999999999999, 'mse = 0.0\\nsamples = 5\\nvalue = 3.0'),\n",
       " Text(314.6616541353384, 117.77999999999999, 'X[3] <= 0.011\\nmse = 0.109\\nsamples = 24\\nvalue = 2.875'),\n",
       " Text(312.14436090225564, 99.66, 'X[1] <= 0.001\\nmse = 0.245\\nsamples = 7\\nvalue = 2.571'),\n",
       " Text(309.62706766917296, 81.53999999999999, 'mse = 0.0\\nsamples = 3\\nvalue = 2.0'),\n",
       " Text(314.6616541353384, 81.53999999999999, 'mse = 0.0\\nsamples = 4\\nvalue = 3.0'),\n",
       " Text(317.17894736842106, 99.66, 'mse = 0.0\\nsamples = 17\\nvalue = 3.0'),\n",
       " Text(307.73909774436095, 135.89999999999998, 'mse = 0.0\\nsamples = 299\\nvalue = 3.0'),\n",
       " Text(329.7654135338346, 154.01999999999998, 'X[2] <= 0.02\\nmse = 0.035\\nsamples = 1109\\nvalue = 2.964'),\n",
       " Text(327.2481203007519, 135.89999999999998, 'X[1] <= 0.001\\nmse = 0.178\\nsamples = 172\\nvalue = 2.767'),\n",
       " Text(324.73082706766917, 117.77999999999999, 'X[3] <= 0.002\\nmse = 0.209\\nsamples = 57\\nvalue = 2.298'),\n",
       " Text(322.2135338345865, 99.66, 'X[0] <= 0.001\\nmse = 0.065\\nsamples = 43\\nvalue = 2.07'),\n",
       " Text(319.6962406015038, 81.53999999999999, 'mse = 0.0\\nsamples = 40\\nvalue = 2.0'),\n",
       " Text(324.73082706766917, 81.53999999999999, 'mse = 0.0\\nsamples = 3\\nvalue = 3.0'),\n",
       " Text(327.2481203007519, 99.66, 'mse = 0.0\\nsamples = 14\\nvalue = 3.0'),\n",
       " Text(329.7654135338346, 117.77999999999999, 'mse = 0.0\\nsamples = 115\\nvalue = 3.0'),\n",
       " Text(332.28270676691733, 135.89999999999998, 'mse = 0.0\\nsamples = 937\\nvalue = 3.0')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# YOUR CODE IN THIS CELL\n",
    "from sklearn import tree\n",
    "clf1 = tree.DecisionTreeRegressor()\n",
    "\n",
    "# Train the model\n",
    "clf1 = clf1.fit(ArrX, ArrY)\n",
    "\n",
    "# after being fitted, predict from a new set of samples\n",
    "clf1.predict([[0,0,0,0], [0,1,0,1], [0, 0.01,0,0]])\n",
    "\n",
    "# plot a visualization of the decision tree\n",
    "tree.plot_tree(clf1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3977e62-f633-4058-bdca-2911a1fe61cf",
   "metadata": {},
   "source": [
    "----\n",
    "## Task: SVM Classifier   (5 Marks)\n",
    "\n",
    "Build an [SVM classifier](https://scikit-learn.org/stable/modules/svm.html#classification) that identifies toxic comments.\\\n",
    "Use the **SVM**'s default parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eae63000-79a2-49ec-9de4-1c231cc3fd4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# EXAMPLE CODE: COMMENT OUT THIS CODE CELL AFTER IMPLEMENTING YOUR CODE BELOW\\n# Code from: https://scikit-learn.org/stable/modules/svm.html#classification\\n\\nfrom sklearn import svm\\n\\n# the dataset  X:features, y:output values we are trying to predict\\nX = [[0.0, 0], [1.2, 1]]\\ny = [0, 1]\\n\\nclf = svm.SVC()\\n\\n# train the model\\nclf.fit(X, y)\\n\\n# after being fitted, predict new values\\nclf.predict([[2., 2.]])\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# EXAMPLE CODE: COMMENT OUT THIS CODE CELL AFTER IMPLEMENTING YOUR CODE BELOW\n",
    "# Code from: https://scikit-learn.org/stable/modules/svm.html#classification\n",
    "\n",
    "from sklearn import svm\n",
    "\n",
    "# the dataset  X:features, y:output values we are trying to predict\n",
    "X = [[0.0, 0], [1.2, 1]]\n",
    "y = [0, 1]\n",
    "\n",
    "clf = svm.SVC()\n",
    "\n",
    "# train the model\n",
    "clf.fit(X, y)\n",
    "\n",
    "# after being fitted, predict new values\n",
    "clf.predict([[2., 2.]])\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c6eaf6-02da-470a-b435-91e6918ea685",
   "metadata": {},
   "source": [
    "**SVM** for regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7965fc32-0c4e-45ac-b29b-7148463a6858",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# EXAMPLE CODE: COMMENT OUT THIS CODE CELL AFTER IMPLEMENTING YOUR CODE BELOW\\n# Code from: https://scikit-learn.org/stable/modules/svm.html#regression\\n\\nfrom sklearn import svm\\n\\n# the dataset  X:features, y:output values we are trying to predict\\nX = [[0, 0], [1, 1]]\\ny = [0, 1.2]\\n\\nclf = svm.SVR()\\n\\n# train the model\\nclf.fit(X, y)\\n\\n# after being fitted, predict new values\\nclf.predict([[2., 2.]])\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# EXAMPLE CODE: COMMENT OUT THIS CODE CELL AFTER IMPLEMENTING YOUR CODE BELOW\n",
    "# Code from: https://scikit-learn.org/stable/modules/svm.html#regression\n",
    "\n",
    "from sklearn import svm\n",
    "\n",
    "# the dataset  X:features, y:output values we are trying to predict\n",
    "X = [[0, 0], [1, 1]]\n",
    "y = [0, 1.2]\n",
    "\n",
    "clf = svm.SVR()\n",
    "\n",
    "# train the model\n",
    "clf.fit(X, y)\n",
    "\n",
    "# after being fitted, predict new values\n",
    "clf.predict([[2., 2.]])\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c13330c-177a-4700-9fe8-b9b623ccfa45",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "    <h4>WRITE CODE</h4>\n",
    "    In the cell below, write the code that implements an SVM classifier.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c3c5a384-6e2b-4724-9f8c-e9fc623773a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.10011607, 2.63015758, 2.40940933])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR CODE IN THIS CELL\n",
    "from sklearn import svm\n",
    "clf2 = svm.SVR()\n",
    "\n",
    "# Train the model\n",
    "clf2.fit(ArrX, ArrY)\n",
    "\n",
    "# Evaluate the model\n",
    "clf2.predict([[0,0,0,0], [0,1,0,1], [0, 0.01,0,0]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e825695a-70ba-4c2c-b7f8-f832edbfdcce",
   "metadata": {},
   "source": [
    "----\n",
    "## Task: Language Model   (20 Marks)\n",
    "\n",
    "Build a *language model* to identify toxic comments.\\\n",
    "Recall that language models can be built using n-grams.\\\n",
    "Also refer to **Chapter 3** in \"[*Speech and Language Processing*](https://web.stanford.edu/~jurafsky/slp3)\" (freely available textbook!) by Jurafsky & Martin for explanations of **N-gram Language Models**.\n",
    "\n",
    "Construct a **Tri-gram** language model with **backoff smoothing**.\\\n",
    "Refer to **Quiz #4** for insights into **n-gram** language models.\n",
    "\n",
    "A breakdown of the marking for this task:\n",
    "* [**15 marks**] trigram language model implemented\n",
    "* [**5 marks**] back-off smoothing implemented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0a6430d2-def8-4da9-ba7b-6701e1d942f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# refer to Quiz #4 for help with n-gram language models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f13fe6-37d1-4d2b-afb5-0d9f4e03868c",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "    <h4>WRITE CODE</h4>\n",
    "    In the cell below, write the code that implements a Tri-gram Language Model.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9abf8031-12c5-46cc-9b4f-bcbda5ad0839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability that the comment contain \"fuck you\" 0.11996154638467349\n"
     ]
    }
   ],
   "source": [
    "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
    "from nltk.lm import MLE\n",
    "\n",
    "trigram = 3\n",
    "bigram = 2\n",
    "unigram = 1\n",
    "\n",
    "# Create a Trigram language model\n",
    "trigramModel = MLE(trigram) \n",
    "\n",
    "for comment in comments:\n",
    "    train_data, padded_sents = padded_everygram_pipeline(trigram, comment)\n",
    "    trigramModel.fit(train_data, padded_sents)\n",
    "\n",
    "# Create a Bigram language model\n",
    "bigramModel = MLE(bigram) \n",
    "\n",
    "for comment in comments:\n",
    "    train_data, padded_sents = padded_everygram_pipeline(trigram, comment)\n",
    "    bigramModel.fit(train_data, padded_sents)\n",
    "\n",
    "# Create a Unigram language model\n",
    "unigramModel = MLE(unigram) \n",
    "\n",
    "for comment in comments:\n",
    "    train_data, padded_sents = padded_everygram_pipeline(trigram, comment)\n",
    "    unigramModel.fit(train_data, padded_sents)\n",
    "\n",
    "# Compute the probability a comment is toxic\n",
    "\n",
    "# Probability that the comment contain \"fuck you\"\n",
    "print(\"Probability that the comment contain \\\"fuck you\\\"\",trigramModel.score('fuck', 'you'.split()))\n",
    "\n",
    "# Evaluate the model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1b8526-2c08-43f6-9574-9d0d20db7d80",
   "metadata": {},
   "source": [
    "----\n",
    "## Task: Random Forest Model   (5 Marks)\n",
    "\n",
    "Build a *random forest model* to identify toxic comments.\n",
    "\n",
    "### Random Forest Classifier\n",
    "\n",
    "The **scikit-learn** implementation of **Random Forest** \"*combines classifiers by averaging their probabilistic prediction, instead of letting each classifier vote for a single class*\".\\\n",
    "Code examples for implementing a **Random Forest Classifier** is [here](https://scikit-learn.org/stable/modules/ensemble.html#forest).\\\n",
    "API information on **Random Forest Classifiers** is [here](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier).\n",
    "\n",
    "\n",
    "### Random Forest Regressor\n",
    "\n",
    "A **Random Forest** model for a regression task is conceptually identical to the classifier version above.\n",
    "\n",
    "\n",
    "### Implementation\n",
    "\n",
    "Using **scikit-learn**, create a **Random Forest** model consisting of the following parameters (model parameters not specified can be left to their default values):\n",
    "* number of estimators = 100\n",
    "\n",
    "\n",
    "**Random Forest** for classification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d8bd7821-c669-475c-937e-b60a97e287c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# EXAMPLE CODE: COMMENT OUT THIS CODE CELL AFTER IMPLEMENTING YOUR CODE BELOW\\n# Code from: https://scikit-learn.org/stable/modules/ensemble.html#forest\\n# Classification\\n\\nfrom sklearn.ensemble import RandomForestClassifier\\n\\nX = [[0, 0], [1, 1]]\\nY = [0, 1]\\n\\nclf = RandomForestClassifier(n_estimators=10)\\n\\nclf = clf.fit(X, Y)\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# EXAMPLE CODE: COMMENT OUT THIS CODE CELL AFTER IMPLEMENTING YOUR CODE BELOW\n",
    "# Code from: https://scikit-learn.org/stable/modules/ensemble.html#forest\n",
    "# Classification\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "X = [[0, 0], [1, 1]]\n",
    "Y = [0, 1]\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=10)\n",
    "\n",
    "clf = clf.fit(X, Y)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e7c905-fcc8-4b00-bc48-dc1ba644ddca",
   "metadata": {},
   "source": [
    "**Random Forest** for regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "64a00f27-fffd-4b01-839b-713769b6bca4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# EXAMPLE CODE: COMMENT OUT THIS CODE CELL AFTER IMPLEMENTING YOUR CODE BELOW\\n# Code from: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html\\n# Regression\\n\\nfrom sklearn.ensemble import RandomForestRegressor\\nfrom sklearn.datasets import make_regression\\nX, y = make_regression(n_features=4, n_informative=2, random_state=0, shuffle=False)\\n\\nregr = RandomForestRegressor(max_depth=2, random_state=0)\\n\\nregr.fit(X, y)\\n\\nprint(regr.predict([[0, 0, 0, 0]]))\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# EXAMPLE CODE: COMMENT OUT THIS CODE CELL AFTER IMPLEMENTING YOUR CODE BELOW\n",
    "# Code from: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html\n",
    "# Regression\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "X, y = make_regression(n_features=4, n_informative=2, random_state=0, shuffle=False)\n",
    "\n",
    "regr = RandomForestRegressor(max_depth=2, random_state=0)\n",
    "\n",
    "regr.fit(X, y)\n",
    "\n",
    "print(regr.predict([[0, 0, 0, 0]]))\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f03d51-a57b-4ba2-96e8-3872b1dff3bf",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "    <h4>WRITE CODE</h4>\n",
    "    In the cell below, write the code that implements a Random Forest Classifier.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e682a15b-88ef-42f1-bd3b-7846fdafaf4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 3 1]\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE IN THIS CELL\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf3 = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "# Train the model\n",
    "clf3 = clf.fit(ArrX, ArrY)\n",
    "\n",
    "# Evaluate the model\n",
    "print(clf3.predict([[0,0,0,0], [0,1,0,1], [0, 0.01,0,0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89880302-4f63-4438-be94-53416166a37c",
   "metadata": {},
   "source": [
    "## Task: Voting Ensemble   (10 Marks)\n",
    "\n",
    "A **Voting Ensemble** classifier \"*combine conceptually different machine learning classifiers and use a majority vote (hard vote) or the average predicted probabilities (soft vote) to predict the class labels*\". \"*In his highly influential Society of Mind theory, Marvin Minsky proposes that human minds are constructed from an ensemble of agents*\" (from \"**AI: A Modern Approach**\" pg. 434, 3rd ed.).\n",
    "\n",
    "From https://scikit-learn.org/stable/modules/ensemble.html#voting-classifier:\n",
    "> *The idea behind the VotingClassifier is to combine conceptually different machine learning classifiers and use a majority vote or the average predicted probabilities (soft vote) to predict the class labels. Such a classifier can be useful for a set of equally well performing model in order to balance out their individual weaknesses.The idea behind the VotingClassifier is to combine conceptually different machine learning classifiers and use a majority vote or the average predicted probabilities (soft vote) to predict the class labels. Such a classifier can be useful for a set of equally well performing model in order to balance out their individual weaknesses.*\n",
    "\n",
    "Using **scikit-learn**, create two **Voting Ensemble Classifiers** (*hard voting* and *soft voting*) consisting of the following models:\n",
    "* SVM classifier\n",
    "* Decision Tree classifier\n",
    "* Random Forest classifier\n",
    "\n",
    "Use the default parameters for both *hard voting* and *soft voting* classifiers.\n",
    "\n",
    "Code examples for implementing a **Voting Ensemble Classifier** is [here](https://scikit-learn.org/stable/modules/ensemble.html#voting-classifier).\\\n",
    "API information on **Voting Ensemble Classifiers** is [here](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html#sklearn.ensemble.VotingClassifier)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4fa1a354",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# EXAMPLE CODE: COMMENT OUT THIS CODE CELL AFTER IMPLEMENTING YOUR CODE BELOW\\n# Code from:  https://scikit-learn.org/stable/modules/ensemble.html#voting-classifier\\n\\nfrom sklearn import datasets\\nfrom sklearn.tree import DecisionTreeClassifier\\nfrom sklearn.neighbors import KNeighborsClassifier\\nfrom sklearn.svm import SVC\\nfrom itertools import product\\nfrom sklearn.ensemble import VotingClassifier\\n\\n# Load some example data\\niris = datasets.load_iris()\\nX = iris.data[:, [0, 2]]\\ny = iris.target\\n\\n# Training classifiers\\nclf1 = DecisionTreeClassifier(max_depth=4)\\nclf2 = KNeighborsClassifier(n_neighbors=7)\\nclf3 = SVC(kernel=\\'rbf\\', probability=True)\\n\\n# The Ensemble classifier\\n# \\'estimator\\' is another name for \\'model\\' or \\'learner\\'\\neclf = VotingClassifier(estimators=[(\\'dt\\', clf1), (\\'knn\\', clf2), (\\'svc\\', clf3)],\\n                        voting=\\'soft\\',\\n                        weights=[2, 1, 2])\\n\\n# train the individual classifiers first\\nclf1 = clf1.fit(X, y)\\nclf2 = clf2.fit(X, y)\\nclf3 = clf3.fit(X, y)\\n# then train the ensemble of the trained classifiers (clf1, clf2, & clf3)\\neclf = eclf.fit(X, y)\\n\\n# make predictions\\nprint(\"Ensemble classifier\\'s predictions:\\n\", eclf.predict(X))\\nprint(\"\\nThe resulting dimensions of the Ensemble classifier:\", eclf.transform(X).shape)\\n'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# EXAMPLE CODE: COMMENT OUT THIS CODE CELL AFTER IMPLEMENTING YOUR CODE BELOW\n",
    "# Code from:  https://scikit-learn.org/stable/modules/ensemble.html#voting-classifier\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from itertools import product\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# Load some example data\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data[:, [0, 2]]\n",
    "y = iris.target\n",
    "\n",
    "# Training classifiers\n",
    "clf1 = DecisionTreeClassifier(max_depth=4)\n",
    "clf2 = KNeighborsClassifier(n_neighbors=7)\n",
    "clf3 = SVC(kernel='rbf', probability=True)\n",
    "\n",
    "# The Ensemble classifier\n",
    "# 'estimator' is another name for 'model' or 'learner'\n",
    "eclf = VotingClassifier(estimators=[('dt', clf1), ('knn', clf2), ('svc', clf3)],\n",
    "                        voting='soft',\n",
    "                        weights=[2, 1, 2])\n",
    "\n",
    "# train the individual classifiers first\n",
    "clf1 = clf1.fit(X, y)\n",
    "clf2 = clf2.fit(X, y)\n",
    "clf3 = clf3.fit(X, y)\n",
    "# then train the ensemble of the trained classifiers (clf1, clf2, & clf3)\n",
    "eclf = eclf.fit(X, y)\n",
    "\n",
    "# make predictions\n",
    "print(\"Ensemble classifier's predictions:\\n\", eclf.predict(X))\n",
    "print(\"\\nThe resulting dimensions of the Ensemble classifier:\", eclf.transform(X).shape)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae8d8d4-b7c0-4b45-bb6b-2716f9304d24",
   "metadata": {},
   "source": [
    "A **Voting Ensemble** example for regression is [found here](https://scikit-learn.org/stable/modules/ensemble.html#voting-regressor)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e9f31572",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# EXAMPLE CODE: COMMENT OUT THIS CODE CELL AFTER IMPLEMENTING YOUR CODE BELOW\\n# Code from:  https://scikit-learn.org/stable/modules/ensemble.html#voting-regressor\\n\\nfrom sklearn.datasets import load_diabetes\\nfrom sklearn.ensemble import GradientBoostingRegressor\\nfrom sklearn.ensemble import RandomForestRegressor\\nfrom sklearn.linear_model import LinearRegression\\nfrom sklearn.ensemble import VotingRegressor\\n\\n# Loading some example data\\nX, y = load_diabetes(return_X_y=True)\\n\\n# Training individual models\\nreg1 = GradientBoostingRegressor(random_state=1)\\nreg2 = RandomForestRegressor(random_state=1)\\nreg3 = LinearRegression()\\n\\n# create an ensemble from the individual models\\nereg = VotingRegressor(estimators=[('gb', reg1), ('rf', reg2), ('lr', reg3)])\\n\\nereg = ereg.fit(X, y)\\n\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# EXAMPLE CODE: COMMENT OUT THIS CODE CELL AFTER IMPLEMENTING YOUR CODE BELOW\n",
    "# Code from:  https://scikit-learn.org/stable/modules/ensemble.html#voting-regressor\n",
    "\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "\n",
    "# Loading some example data\n",
    "X, y = load_diabetes(return_X_y=True)\n",
    "\n",
    "# Training individual models\n",
    "reg1 = GradientBoostingRegressor(random_state=1)\n",
    "reg2 = RandomForestRegressor(random_state=1)\n",
    "reg3 = LinearRegression()\n",
    "\n",
    "# create an ensemble from the individual models\n",
    "ereg = VotingRegressor(estimators=[('gb', reg1), ('rf', reg2), ('lr', reg3)])\n",
    "\n",
    "ereg = ereg.fit(X, y)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fead89e2-b8a8-4fc5-b1b3-812c890b2ab3",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "    <h4>WRITE CODE</h4>\n",
    "    In the cell below, write the code that implements a Voting Ensemble classifier.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d20168e1-9721-47c3-8854-aeb5876abee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Soft\n",
      "Ensemble classifier's predictions:\n",
      " [2 1 0 ... 0 2 1]\n",
      "\n",
      "The resulting dimensions of the Ensemble classifier: (10000, 12)\n",
      "\n",
      "Hard\n",
      "Ensemble classifier's predictions:\n",
      " [2 1 0 ... 0 2 1]\n",
      "\n",
      "The resulting dimensions of the Ensemble classifier: (10000, 3)\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE IN THIS CELL\n",
    "from sklearn import datasets\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from itertools import product\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = ArrX\n",
    "y = ArrY\n",
    "\n",
    "# Train the model\n",
    "vclf1 = DecisionTreeClassifier()\n",
    "vclf2 = RandomForestClassifier()\n",
    "vclf3 = SVC(kernel='rbf', probability=True)\n",
    "\n",
    "eclf1 = VotingClassifier(estimators=[('dt', vclf1), ('rf', vclf2), ('svc', vclf3)],\n",
    "                        voting='soft',\n",
    "                        weights=[1, 1, 1])\n",
    "\n",
    "eclf2 = VotingClassifier(estimators=[('dt', vclf1), ('rf', vclf2), ('svc', vclf3)],\n",
    "                        voting='hard',\n",
    "                        weights=[1, 1, 1])\n",
    "\n",
    "# train the individual classifiers first\n",
    "vclf1 = vclf1.fit(X, y)\n",
    "vclf2 = vclf2.fit(X, y)\n",
    "vclf3 = vclf3.fit(X, y)\n",
    "\n",
    "# then train the ensemble of the trained classifiers (clf1, clf2, & clf3)\n",
    "eclf1 = eclf1.fit(X, y)\n",
    "eclf2 = eclf2.fit(X, y)\n",
    "\n",
    "# Evaluate the model\n",
    "print('Soft')\n",
    "print(\"Ensemble classifier's predictions:\\n\", eclf1.predict(X))\n",
    "print(\"\\nThe resulting dimensions of the Ensemble classifier:\", eclf1.transform(X).shape)\n",
    "print('\\nHard')\n",
    "print(\"Ensemble classifier's predictions:\\n\", eclf2.predict(X))\n",
    "print(\"\\nThe resulting dimensions of the Ensemble classifier:\", eclf2.transform(X).shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77267031-08c9-4a52-a44c-853c94e11f06",
   "metadata": {
    "tags": []
   },
   "source": [
    "----\n",
    "## Task: Neural Network   (5 Marks)\n",
    "\n",
    "Build a *neural network* to identify toxic comments.\n",
    "\n",
    "Note we will be building a *very superficial* neural network model.\\\n",
    "For those interested in learning more, please take **CMPT 410** (Machine Learning) and/or **CMPT 418** (Deep Learning).\n",
    "\n",
    "<!--\n",
    "A [reference tutorial from Google](https://developers.google.com/machine-learning/guides/text-classification/) provides an overview of a text classification workflow\\\n",
    "![](https://developers.google.com/machine-learning/guides/text-classification/images/TextClassificationFlowchart.png).\n",
    "-->\n",
    "\n",
    "The example below uses an existing (*already trained*) model downloaded from **Tensorflow**'s **Hub**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "42864a75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# EXAMPLE CODE: COMMENT OUT THIS CODE CELL AFTER IMPLEMENTING YOUR CODE BELOW\\n# from   https://www.tensorflow.org/tutorials/keras/text_classification_with_hub\\n\\nimport os\\nimport numpy as np\\nimport tensorflow as tf\\nimport tensorflow_hub as hub\\nimport tensorflow_datasets as tfds\\n\\n\\n########################\\n### SET UP THE DATASET\\n########################\\n\\n# Uses the IMDB Movie Reviews dataset\\n# Split the training set into 60% and 40% to get\\n#     15,000 training examples\\n#     10,000 examples for validation\\n#     25,000 testing examples\\ntrain_data, validation_data, test_data = tfds.load( name=\"imdb_reviews\", \\n    split=(\\'train[:60%]\\', \\'train[60%:]\\', \\'test\\'),\\n    as_supervised=True)\\n\\ntrain_examples_batch, train_labels_batch = next(iter(train_data.batch(10)))\\n\\n# print first 10 examples\\nprint(train_examples_batch)\\n# print the first 10 labels\\ntrain_labels_batch\\n\\n\\n####################################\\n### SET UP THE NEURAL NETWORK MODEL\\n####################################\\n\\n# create a Keras layer that uses a TensorFlow Hub model to embed the sentences\\nembedding = \"https://tfhub.dev/google/nnlm-en-dim50/2\"\\nhub_layer = hub.KerasLayer(embedding, input_shape=[], dtype=tf.string, trainable=True)\\nhub_layer(train_examples_batch[:3])\\n\\n# build the full model\\nmodel = tf.keras.Sequential()\\nmodel.add(hub_layer)\\nmodel.add(tf.keras.layers.Dense(16, activation=\\'relu\\'))\\nmodel.add(tf.keras.layers.Dense(1))\\n\\nmodel.summary()\\n\\n# configure the model to use an optimizer and a loss function\\nmodel.compile(optimizer=\\'adam\\',\\n              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\\n              metrics=[\\'accuracy\\'])\\n\\n\\n####################################\\n### TRAIN THE NEURAL NETWORK MODEL\\n####################################\\n\\n# Train the model for 10 epochs in mini-batches of 512 samples\\n# This is 10 iterations (epochs) over all samples in the x_train and y_train tensors\\n# While training, monitor the model\\'s loss and accuracy on the 10,000 samples from the validation set\\nhistory = model.fit(train_data.shuffle(10000).batch(512),\\n                    epochs=10,\\n                    validation_data=validation_data.batch(512),\\n                    verbose=1)\\n\\n\\n######################################\\n### EVALUATE THE NEURAL NETWORK MODEL\\n######################################\\n\\n# Evaluate the model\\n# Two values will be returned:\\n#    Loss (a number which represents our error, lower values are better)\\n#    Accuracy\\nresults = model.evaluate(test_data.batch(512), verbose=2)\\nfor name, value in zip(model.metrics_names, results):\\n    print(\"%s: %.3f\" % (name, value))\\n'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# EXAMPLE CODE: COMMENT OUT THIS CODE CELL AFTER IMPLEMENTING YOUR CODE BELOW\n",
    "# from   https://www.tensorflow.org/tutorials/keras/text_classification_with_hub\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "\n",
    "########################\n",
    "### SET UP THE DATASET\n",
    "########################\n",
    "\n",
    "# Uses the IMDB Movie Reviews dataset\n",
    "# Split the training set into 60% and 40% to get\n",
    "#     15,000 training examples\n",
    "#     10,000 examples for validation\n",
    "#     25,000 testing examples\n",
    "train_data, validation_data, test_data = tfds.load( name=\"imdb_reviews\", \n",
    "    split=('train[:60%]', 'train[60%:]', 'test'),\n",
    "    as_supervised=True)\n",
    "\n",
    "train_examples_batch, train_labels_batch = next(iter(train_data.batch(10)))\n",
    "\n",
    "# print first 10 examples\n",
    "print(train_examples_batch)\n",
    "# print the first 10 labels\n",
    "train_labels_batch\n",
    "\n",
    "\n",
    "####################################\n",
    "### SET UP THE NEURAL NETWORK MODEL\n",
    "####################################\n",
    "\n",
    "# create a Keras layer that uses a TensorFlow Hub model to embed the sentences\n",
    "embedding = \"https://tfhub.dev/google/nnlm-en-dim50/2\"\n",
    "hub_layer = hub.KerasLayer(embedding, input_shape=[], dtype=tf.string, trainable=True)\n",
    "hub_layer(train_examples_batch[:3])\n",
    "\n",
    "# build the full model\n",
    "model = tf.keras.Sequential()\n",
    "model.add(hub_layer)\n",
    "model.add(tf.keras.layers.Dense(16, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# configure the model to use an optimizer and a loss function\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "####################################\n",
    "### TRAIN THE NEURAL NETWORK MODEL\n",
    "####################################\n",
    "\n",
    "# Train the model for 10 epochs in mini-batches of 512 samples\n",
    "# This is 10 iterations (epochs) over all samples in the x_train and y_train tensors\n",
    "# While training, monitor the model's loss and accuracy on the 10,000 samples from the validation set\n",
    "history = model.fit(train_data.shuffle(10000).batch(512),\n",
    "                    epochs=10,\n",
    "                    validation_data=validation_data.batch(512),\n",
    "                    verbose=1)\n",
    "\n",
    "\n",
    "######################################\n",
    "### EVALUATE THE NEURAL NETWORK MODEL\n",
    "######################################\n",
    "\n",
    "# Evaluate the model\n",
    "# Two values will be returned:\n",
    "#    Loss (a number which represents our error, lower values are better)\n",
    "#    Accuracy\n",
    "results = model.evaluate(test_data.batch(512), verbose=2)\n",
    "for name, value in zip(model.metrics_names, results):\n",
    "    print(\"%s: %.3f\" % (name, value))\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a32125-fb29-465f-bc1a-094f39b4f6f9",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "    <h4>WRITE CODE</h4>\n",
    "    In the cell below, write the code that implements a Neural Network.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "89211ebe-e5d2-4692-8619-a4c8618357d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "313/313 [==============================] - 1s 1ms/step - loss: 1.2744\n",
      "Epoch 2/10\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.9885\n",
      "Epoch 3/10\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.9518\n",
      "Epoch 4/10\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.9343\n",
      "Epoch 5/10\n",
      "313/313 [==============================] - 0s 983us/step - loss: 0.9264\n",
      "Epoch 6/10\n",
      "313/313 [==============================] - 0s 986us/step - loss: 0.9221\n",
      "Epoch 7/10\n",
      "313/313 [==============================] - 0s 966us/step - loss: 0.9185 0s - loss: 0.91\n",
      "Epoch 8/10\n",
      "313/313 [==============================] - 0s 966us/step - loss: 0.9161\n",
      "Epoch 9/10\n",
      "313/313 [==============================] - 0s 993us/step - loss: 0.9140\n",
      "Epoch 10/10\n",
      "313/313 [==============================] - 0s 954us/step - loss: 0.9126\n",
      "1/1 - 0s - loss: 0.0000e+00 - 48ms/epoch - 48ms/step\n",
      "Result :  0.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# make numpy values easier to read (prettyprint)\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "\n",
    "# Insert features and Y into dataframe\n",
    "abalone_train = pd.DataFrame()\n",
    "abalone_train.insert(0, 'X0', X0)\n",
    "abalone_train.insert(1, 'X1', X1)\n",
    "abalone_train.insert(2, 'X2', X2)\n",
    "abalone_train.insert(3, 'X3', X3)\n",
    "abalone_train.insert(4, 'Y', ArrY)\n",
    "\n",
    "# Pop 'Y' to predict it\n",
    "abalone_features = abalone_train.copy()\n",
    "abalone_labels = abalone_features.pop('Y')\n",
    "\n",
    "abalone_features = np.array(abalone_features)\n",
    "\n",
    "abalone_model = tf.keras.Sequential([\n",
    "  layers.Dense(64),\n",
    "  layers.Dense(1)\n",
    "])\n",
    "\n",
    "abalone_model.compile(loss = tf.losses.MeanSquaredError(),\n",
    "                      optimizer = tf.optimizers.Adam())\n",
    "\n",
    "# Train Neural Network\n",
    "abalone_model.fit(abalone_features, abalone_labels, epochs=10)\n",
    "\n",
    "# Evaluate the Neural Network\n",
    "results = abalone_model.evaluate([[0,0,0,0], [0,1,0,1], [0, 0.01,0,0]], verbose=2)\n",
    "print(\"Result : \", results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb38b6e-66d2-487f-8b28-fe4a5397a172",
   "metadata": {},
   "source": [
    "----\n",
    "## Task: Naive Bayes Classifier   (5 Marks)\n",
    "\n",
    "Build a **Naive Bayes classifier** to identify toxic comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b03655d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# EXAMPLE CODE: COMMENT OUT THIS CODE CELL AFTER IMPLEMENTING YOUR CODE BELOW\\n# Code from:  https://scikit-learn.org/stable/modules/naive_bayes.html#gaussian-naive-bayes\\n\\nimport numpy as np\\nfrom sklearn.naive_bayes import GaussianNB\\n\\nX = np.array([[-1, -1], [-2, -1], [-3, -2], [1, 1], [2, 1], [3, 2]])\\nY = np.array([1, 1, 1, 2, 2, 2])\\n\\nclf = GaussianNB()\\nclf.fit(X, Y)\\n\\nprint(clf.predict([[-0.8, -1]]))\\n\\nclf_pf = GaussianNB()\\nclf_pf.partial_fit(X, Y, np.unique(Y))\\n\\nprint(clf_pf.predict([[-0.8, -1]]))\\n'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# EXAMPLE CODE: COMMENT OUT THIS CODE CELL AFTER IMPLEMENTING YOUR CODE BELOW\n",
    "# Code from:  https://scikit-learn.org/stable/modules/naive_bayes.html#gaussian-naive-bayes\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "X = np.array([[-1, -1], [-2, -1], [-3, -2], [1, 1], [2, 1], [3, 2]])\n",
    "Y = np.array([1, 1, 1, 2, 2, 2])\n",
    "\n",
    "clf = GaussianNB()\n",
    "clf.fit(X, Y)\n",
    "\n",
    "print(clf.predict([[-0.8, -1]]))\n",
    "\n",
    "clf_pf = GaussianNB()\n",
    "clf_pf.partial_fit(X, Y, np.unique(Y))\n",
    "\n",
    "print(clf_pf.predict([[-0.8, -1]]))\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4753557-4871-4dca-ad24-9b751332bff7",
   "metadata": {},
   "source": [
    "### Regression (Linear Model)\n",
    "\n",
    "For regression, use a **Linear Regression** model instead of *Naive Bayes*.\\\n",
    "A succinct overview of using a [linear model to detect diabetes](https://scikit-learn.org/stable/auto_examples/linear_model/plot_ols.html#sphx-glr-auto-examples-linear-model-plot-ols-py) provides a good explanation of an end-to-end experimental workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fec6d280",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# EXAMPLE CODE: COMMENT OUT THIS CODE CELL AFTER IMPLEMENTING YOUR CODE BELOW\\n# Code from:  https://scikit-learn.org/stable/modules/linear_model.html\\n\\nfrom sklearn import linear_model\\n\\nreg = linear_model.LinearRegression()\\n\\n# train the model with data\\nreg.fit([[0, 0], [1, 1], [2, 2]],\\n        [0, 1, 2])\\n\\n# make predictions\\nprediction = reg.predict([[-0.8, -1]])\\nprint(\"Prediction:\", prediction)\\n'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# EXAMPLE CODE: COMMENT OUT THIS CODE CELL AFTER IMPLEMENTING YOUR CODE BELOW\n",
    "# Code from:  https://scikit-learn.org/stable/modules/linear_model.html\n",
    "\n",
    "from sklearn import linear_model\n",
    "\n",
    "reg = linear_model.LinearRegression()\n",
    "\n",
    "# train the model with data\n",
    "reg.fit([[0, 0], [1, 1], [2, 2]],\n",
    "        [0, 1, 2])\n",
    "\n",
    "# make predictions\n",
    "prediction = reg.predict([[-0.8, -1]])\n",
    "print(\"Prediction:\", prediction)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf1896d-f3c0-48e1-a640-6f3ee19e471d",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "    <h4>WRITE CODE</h4>\n",
    "    In the cell below, write the code that implements a Naive Bayes Classifier.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "48248840-0218-4df6-be5e-a6726206a3b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 3 2]\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE IN THIS CELL\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "X = np.array(ArrX)\n",
    "Y = np.array(ArrY)\n",
    "\n",
    "# Train the model\n",
    "clf4 = GaussianNB()\n",
    "clf4.fit(X, Y)\n",
    "\n",
    "# Evaluate the model\n",
    "\n",
    "print(clf4.predict([[0,0,0,0], [0,1,0,1], [0, 0.01,0,0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dfbb7f7-1b5f-43c0-97ae-47d7813851c0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Task: Evaluation   (10 Marks)\n",
    "\n",
    "The following classification models are to be evaluated (default parameters can be used in both models):\n",
    "* [Gaussian Naive Bayes classifier](https://scikit-learn.org/stable/modules/naive_bayes.html#gaussian-naive-bayes) \n",
    "* [Decision Tree classifier](https://scikit-learn.org/stable/modules/tree.html#classification)\n",
    "* SVM classifier\n",
    "* Tri-gram Language Model\n",
    "* Neural Network classifier\n",
    "* Random Forest classifier\n",
    "* Ensemble Model classifier\n",
    "\n",
    "Models will be *trained* on the **training data**.\\\n",
    "Models will be *evaluated* on the **test data**.\n",
    "\n",
    "<font color=red>**TBD**.<font color=black> The below is *not* the final evaluation method but the one used in the **Kaggle** competition.\n",
    "\n",
    "<font color=lightgray>\n",
    "\n",
    "The evaluation description for the original **Idenifying Toxic Comments** task needs to be updated.\n",
    "    \n",
    "> Submissions are evaluated on the **mean column-wise ROC AUC**.\\\n",
    "> In other words, the score is the **average of the individual AUCs of each predicted column**.\n",
    "> \n",
    "> **Submission File**\n",
    "> \n",
    "> For each id in the test set, you must predict a probability for each of the six possible types of comment toxicity (*toxic, severetoxic, obscene, threat, insult, identityhate*). The columns must be in the same order as shown below. The file should contain a header and have the following format:\n",
    "> \n",
    "> \t\tid,toxic,severe_toxic,obscene,threat,insult,identity_hate\n",
    "> \t\t00001cee341fdb12,0.5,0.5,0.5,0.5,0.5,0.5\n",
    "> \t\t0000247867823ef7,0.5,0.5,0.5,0.5,0.5,0.5\n",
    "> \t\t...\n",
    "> \t\tetc.\n",
    "\n",
    "    \n",
    "<font color=black>\n",
    "\n",
    "### How To Evaluate A Machine Learning Model\n",
    "\n",
    "We will assign a toxicity score to two comments where one of the comments are determined by humans to be more toxic than the other comment.\n",
    "The performance of a model is measured by how many of the comment pairs agree with human rankings.\n",
    "\n",
    "For example, **Comment 1** (from `validation_data.csv`) is given a score of 1.65 &\n",
    "**Comment 2** is given a score of 76, resulting in **Comment 2** being more toxic than **Comment 1**. If this matches the human assessment then we score 1/1. If not, then the score is 0/1.\n",
    "    \n",
    "From the [task's description on **Kaggle**](https://www.kaggle.com/c/jigsaw-toxic-severity-rating/overview/evaluation):\n",
    "> *For each of the approximately 200,000 pair ratings in the ground truth test data, we use your predicted toxicity score to rank the comment pair. The pair receives a 1 if this ranking matches the annotator ranking, or 0 if it does not match.*\n",
    "    \n",
    "The data used in the evaluation comes from `validation_data.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "54821a58-ea33-47f7-a3be-28ed15357a8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# EXAMPLE CODE: COMMENT OUT THIS CODE CELL AFTER IMPLEMENTING YOUR CODE BELOW\\n\\n# keep track of how many comment pairs we correctly rank\\ntotal_correct_comment_pair_rankings = 0\\n\\n# get next pair of comments from validation_data.csv\\n# NOTE: comment1 is from the column corresponding to \"LESS TOXIC\"\\n#       comment2 is from the column corresponding to \"MORE TOXIC\"\\ncomment1 = \"Comment from Wikipedia! (less toxic comment)\"\\ncomment2 = \"ANOTHER Comment from Wikipedia! Swear word: bA$$ (more toxic comment)\"\\n\\n# convert the comment\\'s text into a feature vector e.g., [0, 0, 2.51, 1, ...]\\ncomment1_features = extract_features(comment1)\\ncomment2_features = extract_features(comment2)\\n\\n# compute the toxicity score of each comment\\ntoxicicity_score_of_comment1 = some_model.predict(comment1_features)\\ntoxicicity_score_of_comment2 = some_model.predict(comment2_features)\\n\\nif toxicicity_score_of_comment2 > toxicicity_score_of_comment1:\\n    total_correct_comment_pair_rankings = total_correct_comment_pair_rankings + 1\\n'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# EXAMPLE CODE: COMMENT OUT THIS CODE CELL AFTER IMPLEMENTING YOUR CODE BELOW\n",
    "\n",
    "# keep track of how many comment pairs we correctly rank\n",
    "total_correct_comment_pair_rankings = 0\n",
    "\n",
    "# get next pair of comments from validation_data.csv\n",
    "# NOTE: comment1 is from the column corresponding to \"LESS TOXIC\"\n",
    "#       comment2 is from the column corresponding to \"MORE TOXIC\"\n",
    "comment1 = \"Comment from Wikipedia! (less toxic comment)\"\n",
    "comment2 = \"ANOTHER Comment from Wikipedia! Swear word: bA$$ (more toxic comment)\"\n",
    "\n",
    "# convert the comment's text into a feature vector e.g., [0, 0, 2.51, 1, ...]\n",
    "comment1_features = extract_features(comment1)\n",
    "comment2_features = extract_features(comment2)\n",
    "\n",
    "# compute the toxicity score of each comment\n",
    "toxicicity_score_of_comment1 = some_model.predict(comment1_features)\n",
    "toxicicity_score_of_comment2 = some_model.predict(comment2_features)\n",
    "\n",
    "if toxicicity_score_of_comment2 > toxicicity_score_of_comment1:\n",
    "    total_correct_comment_pair_rankings = total_correct_comment_pair_rankings + 1\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53c5afb-aed8-4287-b637-227c85e004d4",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "    <h4>WRITE CODE</h4>\n",
    "    In the cell below, write the code for evaluating a model.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "3b746513-cfa0-4cd6-847b-b2d301e4d57c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested Cases: 2000\n",
      "Gaussian Naive Bayes classifier Score:  684\n",
      "Decision Tree classifier Score:  710\n",
      "SVM classifier:  954\n",
      "Random Forest classifier:  111\n",
      "Ensemble Model classifier -Soft Vote- Score:  703\n",
      "Ensemble Model classifier -Hard Vote- Score:  703\n"
     ]
    }
   ],
   "source": [
    "# Gaussian Naive Bayes classifier\n",
    "score1 = 0\n",
    "\n",
    "# Decision Tree classifier\n",
    "score2 = 0\n",
    "\n",
    "# SVM classifier\n",
    "score3 = 0\n",
    "\n",
    "# Random Forest classifier\n",
    "score4 = 0\n",
    "\n",
    "# Soft Ensemble Model classifier\n",
    "score5 = 0\n",
    "\n",
    "# Hard Ensemble Model classifier\n",
    "score6 = 0\n",
    "\n",
    "# get next pair of comments from validation_data.csv\n",
    "# NOTE: comment1 is from the column corresponding to \"LESS TOXIC\"\n",
    "#       comment2 is from the column corresponding to \"MORE TOXIC\"\n",
    "\n",
    "# read dataset from file\n",
    "testDF = pd.read_csv('validation_data.csv')\n",
    "testDF = testDF.head(2000)\n",
    "comments1 = testDF['less_toxic'].tolist()\n",
    "comments2 = testDF['more_toxic'].tolist()\n",
    "\n",
    "# Tokenize to words\n",
    "for i in range(len(comments1)):\n",
    "    comments1[i] = str(comments1[i])\n",
    "    comments1[i] = comments1[i].replace(\"\\n\", \" \")\n",
    "    comments1[i] = tk.tokenize(comments1[i])\n",
    "\n",
    "for i in range(len(comments2)):\n",
    "    comments2[i] = str(comments2[i])\n",
    "    comments2[i] = comments2[i].replace(\"\\n\", \" \")\n",
    "    comments2[i] = tk.tokenize(comments2[i])\n",
    "\n",
    "# Remove punctuations and white spaces\n",
    "for tokens in comments1:\n",
    "    for i in range(len(tokens)):\n",
    "        tokens[i] = tokens[i].strip(\"\\\")(.*,\\' \")\n",
    "        tokens[i] = tokens[i].lower()\n",
    "    while(\"\" in tokens) :\n",
    "        tokens.remove(\"\")\n",
    "        \n",
    "for tokens in comments2:\n",
    "    for i in range(len(tokens)):\n",
    "        tokens[i] = tokens[i].strip(\"\\\")(.*,\\' \")\n",
    "        tokens[i] = tokens[i].lower()\n",
    "    while(\"\" in tokens) :\n",
    "        tokens.remove(\"\")\n",
    "\n",
    "# convert the comment's text into a feature vector e.g., [0, 0, 2.51, 1, ...]\n",
    "\n",
    "# Feature 1\n",
    "LX0 = [] # Feature 1: Comment including bad words\n",
    "for comment in comments1:\n",
    "    score = 0\n",
    "    for token in comment:\n",
    "        if token in badwords:\n",
    "            score += 1\n",
    "    LX0.append(score)\n",
    "\n",
    "MX0 = [] # Feature 1: Comment including bad words\n",
    "for comment in comments2:\n",
    "    score = 0\n",
    "    for token in comment:\n",
    "        if token in badwords:\n",
    "            score += 1\n",
    "    MX0.append(score)\n",
    "\n",
    "# Feature 2\n",
    "LX1 = [] # Feature 3: Comment including negative words\n",
    "for comment in comments1:\n",
    "    score = 0\n",
    "    for token in comment:\n",
    "        if token in negativewords:\n",
    "            score += 1\n",
    "    LX1.append(score)\n",
    "\n",
    "MX1 = [] # Feature 3: Comment including negative words\n",
    "for comment in comments2:\n",
    "    score = 0\n",
    "    for token in comment:\n",
    "        if token in negativewords:\n",
    "            score += 1\n",
    "    MX1.append(score)\n",
    "\n",
    "# Feature 3\n",
    "LX2 = [] # Feature 3: punctuation is used in the body of a word\n",
    "character_string = '?!@$%^#+():;-_\\\"&*<>{}[]`~|/.,' \n",
    "for comment in comments1:\n",
    "    score = 0\n",
    "    for token in comment:\n",
    "        for i in range(len(token)-1):\n",
    "            if token[i] in character_string:\n",
    "                score += 1\n",
    "    LX2.append(score)\n",
    "\n",
    "MX2 = [] # Feature 3: punctuation is used in the body of a word\n",
    "character_string = '?!@$%^#+():;-_\\\"&*<>{}[]`~|/.,' \n",
    "for comment in comments2:\n",
    "    score = 0\n",
    "    for token in comment:\n",
    "        for i in range(len(token)-1):\n",
    "            if token[i] in character_string:\n",
    "                score += 1\n",
    "    MX2.append(score)\n",
    "\n",
    "# Feature 4\n",
    "LX3 = [] # Feature 3: Amount of exclamation marks\n",
    "for comment in comments1:\n",
    "    score = 0\n",
    "    for token in comment:\n",
    "        score += token.count('!')\n",
    "    LX3.append(score)\n",
    "\n",
    "MX3 = [] # Feature 3: Amount of exclamation marks\n",
    "for comment in comments2:\n",
    "    score = 0\n",
    "    for token in comment:\n",
    "        score += token.count('!')\n",
    "    MX3.append(score)\n",
    "\n",
    "LX0 = normalize(LX0, 0, 1)\n",
    "LX1 = normalize(LX1, 0, 1)\n",
    "LX2 = normalize(LX2, 0, 1)\n",
    "LX3 = normalize(LX3, 0, 1)\n",
    "MX0 = normalize(MX0, 0, 1)\n",
    "MX1 = normalize(MX1, 0, 1)\n",
    "MX2 = normalize(MX2, 0, 1)\n",
    "MX3 = normalize(MX3, 0, 1)\n",
    "\n",
    "LArrX = []\n",
    "MArrX = []\n",
    "\n",
    "for i in range(len(LX0)):\n",
    "    LArrX.append([LX0[i], LX1[i], LX2[i], LX3[i]])\n",
    "    MArrX.append([MX0[i], MX1[i], MX2[i], MX3[i]])\n",
    "\n",
    "# compute the toxicity score of each comment\n",
    "\n",
    "# Evaluate Gaussian Naive Bayes classifier\n",
    "less1 = clf4.predict(LArrX)\n",
    "more1 = clf4.predict(MArrX)\n",
    "\n",
    "for i in range(len(less1)):\n",
    "    if more1[i] > less1[i]:\n",
    "        score1 = score1 + 1\n",
    "        \n",
    "# Decision Tree classifier\n",
    "less2 = clf1.predict(LArrX)\n",
    "more2 = clf1.predict(MArrX)\n",
    "\n",
    "for i in range(len(less2)):\n",
    "    if more2[i] > less2[i]:\n",
    "        score2 = score2 + 1\n",
    "        \n",
    "# SVM classifier\n",
    "less3 = clf2.predict(LArrX)\n",
    "more3 = clf2.predict(MArrX)\n",
    "\n",
    "for i in range(len(less3)):\n",
    "    if more3[i] > less3[i]:\n",
    "        score3 = score3 + 1\n",
    "\n",
    "# Random Forest classifier\n",
    "less4 = clf3.predict(LArrX)\n",
    "more4 = clf3.predict(MArrX)\n",
    "\n",
    "for i in range(len(less4)):\n",
    "    if more4[i] > less4[i]:\n",
    "        score4 = score4 + 1\n",
    "\n",
    "# Ensemble Model classifier\n",
    "less5 = eclf1.predict(LArrX)\n",
    "more5 = eclf1.predict(MArrX)\n",
    "less6 = eclf2.predict(LArrX)\n",
    "more6 = eclf2.predict(MArrX)\n",
    "\n",
    "for i in range(len(less5)):\n",
    "    if more5[i] > less5[i]:\n",
    "        score5 = score5 + 1\n",
    "\n",
    "for i in range(len(less6)):\n",
    "    if more6[i] > less6[i]:\n",
    "        score6 = score6 + 1\n",
    "\n",
    "print(\"Tested Cases: 2000\")\n",
    "print(\"Gaussian Naive Bayes classifier Score: \", score1)\n",
    "print(\"Decision Tree classifier Score: \", score2)\n",
    "print(\"SVM classifier: \", score3)\n",
    "print(\"Random Forest classifier: \", score4)\n",
    "print(\"Ensemble Model classifier -Soft Vote- Score: \", score5)\n",
    "print(\"Ensemble Model classifier -Hard Vote- Score: \", score6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e17568c-6bc9-4f8b-af7c-a5e0745a569c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "----\n",
    "# Task: Project Report   \n",
    "\n",
    "The total marks for all of the sections below is **80 Marks**.\n",
    "\n",
    "This section corresponds to the write-up of the project. Your write-up is to be included within this **Jupyter Notebook** below (the code for this assignment is in the code cells above).\\\n",
    "The **Project Report** will consist of a few sections that each discuss a different stage of the end-to-end experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7cdacf-58cd-4226-b9d0-f5081a9d196f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Overview    (5 Marks)\n",
    "\n",
    "Discuss:\n",
    "* the problem/task you are addressing\n",
    "* provide concrete examples of the problem\n",
    "* why the problem is worth the time and effort trying to solve\n",
    "* compare the task with other tasks that are similar\n",
    "\n",
    "The following are optional:\n",
    "* *Related Work* i.e., what have other people tried\n",
    "* historical background of the problem\n",
    "* discuss strategies used in other tasks that are similar to **Toxic Comment Identification**\n",
    "* discuss the differences with those tasks that are similar to **Toxic Comment Identification**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d3cf30-88c1-4bac-b854-ee03add22f8f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Dataset    (5 Marks)\n",
    "\n",
    "Discuss:\n",
    "* the dataset's size\n",
    "* languages dataset contains\n",
    "* anything unusual about the data\n",
    "* how representative the dataset is of everyday communication\n",
    "* etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dbcaf12-1c62-4a31-a18b-8d4036f17590",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Features    (5 Marks)\n",
    "\n",
    "Discuss:\n",
    "* the features that were extracted\n",
    "* the number of features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa3979f-0844-4cc9-9029-0bae2e1af800",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Models    (5 Marks)\n",
    "\n",
    "Discuss:\n",
    "* the models used\n",
    "* any specific parameters, configuration, or settings of each model\n",
    "* any differences in how each model was trained"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6adfef-dd91-4803-b341-fae364ee2370",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Evaluation    (5 Marks)\n",
    "\n",
    "This section discusses:\n",
    "* how you evaluated the models in order to compare their relative performance\n",
    "* evaluating models based on *overall performance*\n",
    "* use visuals, tables, charts, graphs, etc. to communicate results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf8ed7f-317d-4778-8ac9-96ca60248877",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Discussion    (15 Marks)\n",
    " \n",
    "Compare the performance of the above models on **Identifying Toxic Comments**.\\\n",
    "Use visuals, charts, graphs, etc. to communicate your results.\n",
    "\n",
    "Discuss:\n",
    "* your findings in general\n",
    "* compare the performance of the various models (was the performance what you expected?)\n",
    "* which system performed best? why?\n",
    "* which system had the worst performance? why?\n",
    "* discuss the reasons which lead to the results from the evaluation\n",
    "* provide some ideas you would like to have tried (provided you had more time or resources) that could potentially improve the performance of the models or a question that you were interested in exploring (i.e., *Future Work*)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72dbea51-7f7a-4e75-9d1c-2ce85f3f9ff5",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Plotting & Visualizations\n",
    "\n",
    "Examples of various plots and visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "bd0b520c-2c0b-43cf-9487-ce93fe4a5c97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# EXAMPLE CODE: COMMENT OUT THIS CODE CELL AFTER IMPLEMENTING YOUR CODE BELOW\\n\\n# TODO add example visuals\\n\\nimport seaborn\\n\\n# Load example miles per gallon dataset\\nmpg = seaborn.load_dataset(\"mpg\")\\n\\n# Plot miles per gallon against horsepower\\nseaborn.relplot(x=\"horsepower\", y=\"mpg\", hue=\"origin\", size=\"weight\", sizes=(40, 400), alpha=0.4, data=mpg)\\n\\n# Display joint distribution of the features\\nseaborn.pairplot(mpg, diag_kind=\\'kde\\')\\n'"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# EXAMPLE CODE: COMMENT OUT THIS CODE CELL AFTER IMPLEMENTING YOUR CODE BELOW\n",
    "\n",
    "# TODO add example visuals\n",
    "\n",
    "import seaborn\n",
    "\n",
    "# Load example miles per gallon dataset\n",
    "mpg = seaborn.load_dataset(\"mpg\")\n",
    "\n",
    "# Plot miles per gallon against horsepower\n",
    "seaborn.relplot(x=\"horsepower\", y=\"mpg\", hue=\"origin\", size=\"weight\", sizes=(40, 400), alpha=0.4, data=mpg)\n",
    "\n",
    "# Display joint distribution of the features\n",
    "seaborn.pairplot(mpg, diag_kind='kde')\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dac2106-1c27-468d-99d7-299992efc546",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "    <h1>YOUR PROJECT REPORT BEGINS BELOW THIS CELL</h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6649d70c-a699-4246-b5c1-751abf71a6ce",
   "metadata": {},
   "source": [
    "**INFORMATION**\\\n",
    "Student Name: Chang Suk Lee\\\n",
    "Student ID: 301382707\\\n",
    "Student SFU Email: csl33@sfu.ca\n",
    "\n",
    "# Overview\n",
    "\n",
    "The goal of this project is to identify the toxic comments using machine learning technology. The online harrassment and abuse are serious problem. According to a Pew Research Center survey of 2017, about 41% of U.S. adults experienced some form of online harassment in at least one of the six key ways: physical threats, stalking, sustained harrassment, sexual harassment, offensive name-calling, and purposeful embrassment. Moreover, a Pew Research Center's survey of 2020 shows that percentage of adults experienced onlin harassment remained about same, but the severity of the harassment has increased eversince. By help of machine learning technology, the amount of toxic comments on the internet could be dramaticaly decreased.\n",
    "\n",
    "However, it is not an easy task to identify the toxic comments. It would be easy to identify the toxic comments with well known swears such as f-words. Comment like \"Fuck you. Go to hell.\" is an example. However, the comments can be toxic without using swears. For example, \"I think you have a bad personality. I wish you will fail.\" is a toxic comment without using any swears. Moreover, the new words to embrass people are being created frequently. For example, \"wiki NOOBS wiki NOOBS wiki NOOBS wiki NOOBS wiki NOOBS wiki\" contains word 'NOOBS' which refers to the idea that someone is new to a game, concept, or idea. Therefore, the list of these negative words must be updated and trained to AI periodically.\n",
    "\n",
    "Therefore, identifying toxic comments is not an easy challenge but worth the time and effort to solve because if would protect lots of internet users. Also, we could provide better and cleaner online environment to our next generation.\n",
    "\n",
    "The simialr problem to this is predicting closed questions on stack overflow, which analyze the question and predict the likelyhood of that question will be answered and closed.\n",
    "Link: https://www.kaggle.com/c/predict-closed-questions-on-stack-overflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661b9913-05e0-4115-be2c-f7ed21fe049f",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "\n",
    "To train the AI, the train.csv was used which is csv file of 158929 of English comments. Using the whole 158929 comments took forever to train the AI. Therefore, first 10000 comments out of 158929 comments were used to train the AI. The data is consist of both toxic and non-toxic comments. The concern is that it is not verified that the top 10000 comments contains well mixed comments of both non-toxic, toxic, and very toxic comments. If the first 10000 comments happen to be made up of mostly non-toxic or toxic comments, it would not be an ideal data to train the AI. However, it was impossible to humanly check that the first top 10000 comments were ideal data. It was a sacrifice that needed to be made to train AI in reasonable amouunt of time.\n",
    "\n",
    "To evaluate the AI, the data from Jigsaw's fourth Kaggle competition was used. The data is made up of 30287 pairs of less toxic comment and more toxic comment which are socred by a human. The evaluation was done by how accurately the AI socre the less toxic comment less than the more toxic comment. Only the top 2000 pairs were evaluated because of the time the program took to execute."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c309297-f6a7-4b7f-a15e-5dde113f3733",
   "metadata": {},
   "source": [
    "# Features\n",
    "\n",
    "Total of four features were extracted from the data. The first feature was the amount of swear words such as \"fuck\", \"bitch\", or \"cunt\" in the sentence. Since the use of swears in the comment is definitely toxic, this feature was set to significantly affect the toxicity score of the comment. The second feature was the amount of negative words such as \"bad\", \"stink\", or \"dirty\" inside the comment. The third feature was the amount of special characters used as the body of the word inside the comments. For example, \"F%%%\", \"AssW&&&&&\", or \"C&&&&\" are included in this feature. Lastly, the fourth feature is the amount of exclamation mark used inside the comment. For example, \"You are so dumb!!!!!!!\" or \"OMG!!!! You btich!!!\" are included in this feature. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3701e74d-ec62-4ef6-8781-fe01d6961d3d",
   "metadata": {},
   "source": [
    "# Models\n",
    "\n",
    "The models used to predict the toxic comments are: \"Gaussian Naive Bayes Classifier\", \"Decision Tree Classifier\", \"SVM Classifier\", \"Random Forest Classifier\", \"Ensemble Model classifier\". The Language Model and Neural Network were implemented but not used because meaningful prediction could not be produced from them due to my lack of knowledges and errors.\n",
    "\n",
    "Settings:\n",
    "\n",
    "1. \"Gaussian Naive Bayes Classifier\"\n",
    "\n",
    "The Gaussian Naive Bayes Classifier model was used with default setting.\n",
    "\n",
    "2. \"Decision Tree Classifier\"\n",
    "\n",
    "Regression with Decision Trees model was used with default setting.\n",
    "\n",
    "3. \"SVM Classifier\"\n",
    "\n",
    "The SVM Classifier model was used with default setting.\n",
    "\n",
    "4. \"Random Forest Classifier\"\n",
    "\n",
    "The Gaussian Naive Bayes Classifier model was used with default setting with 100 estimators.\n",
    "\n",
    "5. \"Ensemble Model classifier\"\n",
    "\n",
    "The Ensemble Model classifier model was used with both of soft vote and hard vote setting.\n",
    "Each Ensemble Model classifier are made up of three classifiers: SVM classifier, Decision Tree classifier, and Random Forest classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76733eb8-7d58-44bd-aa78-a28f769365d2",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "\n",
    "Here is the result of the evaluation on first 2000 pair of comments out of 30287 pairs of comments.\n",
    "\n",
    "1. SVM Classifier: 954 out of 2000\n",
    "2. Decision Tree Classifier: 710 out of 2000\n",
    "3. Ensemble Model Classifier : 703 out of 2000 (Both soft vote and hard vote)\n",
    "4. Gaussian Naive Bayes Classifier: 684\n",
    "5. Random Forest Classifier: 111\n",
    "\n",
    "The SVM Classifier resulted in best performance of 954 correct result out of 2000 pairs. The Random Forest Classifier did the word which result in 111 correct results out of 200 pairs. Decision Tree classifier, ensemble model classifier, and Gaussian Naive Bayes Classifer resulted in similar performance of aroun 700 correct results out of 2000 pairs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4bc40af-41a6-422a-9e1a-92950cc2a7ec",
   "metadata": {},
   "source": [
    "# Conclusion \n",
    "\n",
    "The performance of the models used in this project was a lot lower than was expected. The models were expected to correctly predict at least 50% of the test cases. However, the models implemented in this project failed to to that. The suspected reason of the low performance of the model is because of poor feature extraction and assigning toxicity score to them. Only four features were extracted out of the data. At first, it seemes that it was enough to identify the toxic comments but it was not accurate. Also, it was hard to correctly assigning the weight of toxicity score to each features. For example, it was very vague to identify if existence of negative words is a stronger factor than the amount of exclamation marks used in the sentence. In this proejct, four cartegories were used to classify the toxic comments: non-toxic, somewhat toxic, toxic, and very toxic. After extracting the feature, the result showed that there were 2235 non-toxic comments, 3640 somewhat toxic comments, 1989 toxic comments, and 2136 very toxic comments in the 10000 training data. However, it was really time-consuming to humanly check if those results were correct. It would take numerous trial and errors to correctly guess the toxcitiy of the comments and obtain the correct toxicity score weight to each features. However, it could not be done due to lack of computing power. In future, if there is a access to much faster computer, it would be possible to conduct more trial and errors with bigger training data.\n",
    "\n",
    "The model which perform the best was SVM classifier which scored 954 out of 2000 pairs. The reason why the Support Vector Machine classifier did the best is because the X array produced by the feature extraction were linearly inseparable. The SVM classifier is specialized in this case and that is why it performed the best.\n",
    "\n",
    "The model which perform the worst was Random Forest Classifier which scored 111 out of 2000 pairs. The reason why the Random Forest Classifier failed to perform well is because the data were linearly inseparable. The Random Forest Classifier assign each node randomly selected number of attributes. As a result, each estimator are likely to comes up with wrong prediction. As a result, Random Forest Classifier could not perform well with the data used in this project.\n",
    "\n",
    "In the future, I would like to work on this project with more team member. If the workload could be distributed, the overall accuracy of the model will be increased because more time can be invested on extracting features, testing models, and evaluating them. Also, it would be very beneficial to have access to fast computer because the amount of the data needed to handle were huge and it was really time consuming to train AI and evaluating AI on normal computer. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
